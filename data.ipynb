{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your main report\n",
    "df = pd.read_csv(\"20250514-report.csv\")\n",
    "df = df[df['end_location']== \" Off Location \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                id  visit_id visit_created    date_captured  \\\n",
      "252  lblID-1195330    352670     14/5/2025  14/5/2025 14:38   \n",
      "253  lblID-1195392    352670     14/5/2025  14/5/2025 14:35   \n",
      "254  lblID-1195388    352670     14/5/2025  14/5/2025 14:42   \n",
      "255  lblID-1195386    352670     14/5/2025  14/5/2025 14:35   \n",
      "256  lblID-1195385    352670     14/5/2025  14/5/2025 14:40   \n",
      "\n",
      "                                         end_image_url  \\\n",
      "252  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "253  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "254  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "255  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "256  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "\n",
      "                                       label_image_url store_type  \\\n",
      "252  https://dtexg3-images.s3.ap-southeast-2.amazon...      Coles   \n",
      "253  https://dtexg3-images.s3.ap-southeast-2.amazon...      Coles   \n",
      "254  https://dtexg3-images.s3.ap-southeast-2.amazon...      Coles   \n",
      "255  https://dtexg3-images.s3.ap-southeast-2.amazon...      Coles   \n",
      "256  https://dtexg3-images.s3.ap-southeast-2.amazon...      Coles   \n",
      "\n",
      "     store_type_id store_suburb  store_postcode  ...        label_type  \\\n",
      "252             15      Croydon            3136  ...           30%_off   \n",
      "253             15      Croydon            3136  ...           30%_off   \n",
      "254             15      Croydon            3136  ...        half_price   \n",
      "255             15      Croydon            3136  ...        half_price   \n",
      "256             15      Croydon            3136  ...  special_multibuy   \n",
      "\n",
      "           brand                           product_name pack_size  \\\n",
      "252         OREO         OREO PASCALL MARSHMALLOWS SLUG      131G   \n",
      "253        VICKS                VICKS VAPOUR SHOWER 5PK     5PACK   \n",
      "254  DARRELL LEA  DARRELL LEA MILK CHOCOLATE LOVE HEART      100G   \n",
      "255   BLACKMORES      LYP-SINE COLD SORE RELIEF TABLETS   30 PACK   \n",
      "256     RED BULL     SUGAR FREE ENERGY DRINK SINGLE CAN     250ML   \n",
      "\n",
      "    current_price was_price unit_price savings multibuy_unit multibuy_price  \n",
      "252             2         3          0       1             0              0  \n",
      "253          10.5        15          0     4.5             0              0  \n",
      "254           4.5         9        4.5     4.5             0              0  \n",
      "255             7        14      23.33       7             0              0  \n",
      "256          3.25         0       3.25       1             2            5.5  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "   visit_id            id visit_created   date_captured  \\\n",
      "0    352623  incID-811798     14/5/2025  14/5/2025 7:31   \n",
      "1    352624  incID-811814     14/5/2025  14/5/2025 7:34   \n",
      "2    352626  incID-811820     14/5/2025  14/5/2025 7:36   \n",
      "3    352627  incID-811822     14/5/2025  14/5/2025 7:37   \n",
      "4    352628  incID-812026     14/5/2025  14/5/2025 7:38   \n",
      "\n",
      "                                       end_image_url  \\\n",
      "0  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "1  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "2  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "3  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "4  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "\n",
      "                                     label_image_url store_type  \\\n",
      "0  https://dtexg3-images.s3.ap-southeast-2.amazon...  Woolworth   \n",
      "1                                                  -  Woolworth   \n",
      "2  https://dtexg3-images.s3.ap-southeast-2.amazon...  Woolworth   \n",
      "3  https://dtexg3-images.s3.ap-southeast-2.amazon...  Woolworth   \n",
      "4  https://dtexg3-images.s3.ap-southeast-2.amazon...  Woolworth   \n",
      "\n",
      "   store_type_id store_suburb  store_postcode  ... label_type brand  \\\n",
      "0             13       Camden            2570  ...          -     -   \n",
      "1             13       Camden            2570  ...          -     -   \n",
      "2             13       Camden            2570  ...          -     -   \n",
      "3             13       Camden            2570  ...          -     -   \n",
      "4             13       Camden            2570  ...          -     -   \n",
      "\n",
      "  product_name pack_size current_price was_price unit_price savings  \\\n",
      "0            -         -             -         -          -       -   \n",
      "1            -         -             -         -          -       -   \n",
      "2            -         -             -         -          -       -   \n",
      "3            -         -             -         -          -       -   \n",
      "4            -         -             -         -          -       -   \n",
      "\n",
      "  multibuy_unit multibuy_price  \n",
      "0             -              -  \n",
      "1             -              -  \n",
      "2             -              -  \n",
      "3             -              -  \n",
      "4             -              -  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filter labels (sku != '-')\n",
    "labels_df = df[df['sku'] != '-'].copy()\n",
    "\n",
    "# Filter ends (sku == '-')\n",
    "ends_df = df[df['sku'] == '-'].copy()\n",
    "\n",
    "# Optional: Select the first end per visit (or use heuristics later)\n",
    "ends_unique = ends_df.sort_values('date_captured').groupby('visit_id').first().reset_index()\n",
    "\n",
    "# Check structure\n",
    "print(labels_df.head())\n",
    "print(ends_unique.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              id  visit_id visit_created    date_captured  \\\n",
      "0  lblID-1195330    352670     14/5/2025  14/5/2025 14:38   \n",
      "1  lblID-1195392    352670     14/5/2025  14/5/2025 14:35   \n",
      "2  lblID-1195388    352670     14/5/2025  14/5/2025 14:42   \n",
      "3  lblID-1195386    352670     14/5/2025  14/5/2025 14:35   \n",
      "4  lblID-1195385    352670     14/5/2025  14/5/2025 14:40   \n",
      "\n",
      "                                 label_end_image_url  \\\n",
      "0  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "1  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "2  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "3  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "4  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "\n",
      "                                     label_image_url store_type  \\\n",
      "0  https://dtexg3-images.s3.ap-southeast-2.amazon...      Coles   \n",
      "1  https://dtexg3-images.s3.ap-southeast-2.amazon...      Coles   \n",
      "2  https://dtexg3-images.s3.ap-southeast-2.amazon...      Coles   \n",
      "3  https://dtexg3-images.s3.ap-southeast-2.amazon...      Coles   \n",
      "4  https://dtexg3-images.s3.ap-southeast-2.amazon...      Coles   \n",
      "\n",
      "   store_type_id store_suburb  store_postcode  ...        brand  \\\n",
      "0             15      Croydon            3136  ...         OREO   \n",
      "1             15      Croydon            3136  ...        VICKS   \n",
      "2             15      Croydon            3136  ...  DARRELL LEA   \n",
      "3             15      Croydon            3136  ...   BLACKMORES   \n",
      "4             15      Croydon            3136  ...     RED BULL   \n",
      "\n",
      "                            product_name pack_size current_price was_price  \\\n",
      "0         OREO PASCALL MARSHMALLOWS SLUG      131G             2         3   \n",
      "1                VICKS VAPOUR SHOWER 5PK     5PACK          10.5        15   \n",
      "2  DARRELL LEA MILK CHOCOLATE LOVE HEART      100G           4.5         9   \n",
      "3      LYP-SINE COLD SORE RELIEF TABLETS   30 PACK             7        14   \n",
      "4     SUGAR FREE ENERGY DRINK SINGLE CAN     250ML          3.25         0   \n",
      "\n",
      "  unit_price savings multibuy_unit multibuy_price  \\\n",
      "0          0       1             0              0   \n",
      "1          0     4.5             0              0   \n",
      "2        4.5     4.5             0              0   \n",
      "3      23.33       7             0              0   \n",
      "4       3.25       1             2            5.5   \n",
      "\n",
      "                               correct_end_image_url  \n",
      "0  https://dtexg3-images.s3.ap-southeast-2.amazon...  \n",
      "1  https://dtexg3-images.s3.ap-southeast-2.amazon...  \n",
      "2  https://dtexg3-images.s3.ap-southeast-2.amazon...  \n",
      "3  https://dtexg3-images.s3.ap-southeast-2.amazon...  \n",
      "4  https://dtexg3-images.s3.ap-southeast-2.amazon...  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge labels with ends on visit_id\n",
    "final_df = labels_df.merge(\n",
    "    ends_unique[['visit_id', 'end_image_url']],  # Only bring end_image_url\n",
    "    on='visit_id',\n",
    "    how='left',\n",
    "    suffixes=('', '_correct_end')\n",
    ")\n",
    "\n",
    "# Final table has: label_image_url, end_image_url (label's own), end_image_url_correct_end (true full display)\n",
    "final_df = final_df.rename(columns={'end_image_url': 'label_end_image_url', 'end_image_url_correct_end': 'correct_end_image_url'})\n",
    "\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "606"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('final.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l6/jvk_psqj1mz2tbsrq4j601_w0000gn/T/ipykernel_48673/2145901636.py:4: UserWarning: Parsing dates in %d/%m/%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df = pd.read_csv(\"20250514-report.csv\", parse_dates=['date_captured'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   visit_id                                    label_image_url  \\\n",
      "1    352718  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "2    352718  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "3    352677  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "4    352677  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "5    352677  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "\n",
      "                               matched_end_image_url       date_captured  \n",
      "1  https://dtexg3-images.s3.ap-southeast-2.amazon... 2025-05-14 14:28:00  \n",
      "2  https://dtexg3-images.s3.ap-southeast-2.amazon... 2025-05-14 14:29:00  \n",
      "3  https://dtexg3-images.s3.ap-southeast-2.amazon... 2025-05-14 14:30:00  \n",
      "4  https://dtexg3-images.s3.ap-southeast-2.amazon... 2025-05-14 14:29:00  \n",
      "5  https://dtexg3-images.s3.ap-southeast-2.amazon... 2025-05-14 14:30:00  \n",
      "âœ… Final mapping saved as 'label_to_correct_end_mapping.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your report CSV\n",
    "df = pd.read_csv(\"20250514-report.csv\", parse_dates=['date_captured'])\n",
    "\n",
    "# Split Labels and Ends\n",
    "labels_df = df[df['sku'] != '-'].copy()\n",
    "ends_df = df[df['sku'] == '-'].copy()\n",
    "\n",
    "# Function: Find the best matching end for a label\n",
    "def find_best_end(label_row, ends_df, time_window='5min'):\n",
    "    visit_id = label_row['visit_id']\n",
    "    label_time = label_row['date_captured']\n",
    "    \n",
    "    # Filter ends by visit_id\n",
    "    candidate_ends = ends_df[ends_df['visit_id'] == visit_id].copy()\n",
    "    \n",
    "    # Filter ends within time window\n",
    "    candidate_ends = candidate_ends[\n",
    "        (candidate_ends['date_captured'] >= label_time - pd.Timedelta(time_window)) &\n",
    "        (candidate_ends['date_captured'] <= label_time + pd.Timedelta(time_window))\n",
    "    ]\n",
    "    \n",
    "    if not candidate_ends.empty:\n",
    "        # Return the earliest end in time window\n",
    "        return candidate_ends.sort_values('date_captured').iloc[0]['end_image_url']\n",
    "    else:\n",
    "        # Fallback: Return earliest end in entire visit\n",
    "        fallback_end = ends_df[ends_df['visit_id'] == visit_id].sort_values('date_captured')\n",
    "        if not fallback_end.empty:\n",
    "            return fallback_end.iloc[0]['end_image_url']\n",
    "        else:\n",
    "            return None  # No end found at all\n",
    "\n",
    "# Apply matching logic to all labels\n",
    "labels_df['matched_end_image_url'] = labels_df.apply(\n",
    "    lambda row: find_best_end(row, ends_df),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Final Result\n",
    "final_mapping = labels_df[['visit_id', 'label_image_url', 'matched_end_image_url', 'date_captured']]\n",
    "print(final_mapping.head())\n",
    "\n",
    "# Save to CSV\n",
    "final_mapping.to_csv(\"label_to_correct_end_mapping.csv\", index=False)\n",
    "print(\"âœ… Final mapping saved as 'label_to_correct_end_mapping.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv('merged_dashboard_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "def load_image_from_url(url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        img_array = np.asarray(bytearray(response.content), dtype=np.uint8)\n",
    "        img = cv2.imdecode(img_array, cv2.IMREAD_GRAYSCALE)\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to load image from URL: {url} | Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def compute_template_match_score(label_url, end_url):\n",
    "    label = load_image_from_url(label_url)\n",
    "    end = load_image_from_url(end_url)\n",
    "    \n",
    "    if label is None or end is None:\n",
    "        return np.nan\n",
    "\n",
    "    if label.shape[0] > end.shape[0] or label.shape[1] > end.shape[1]:\n",
    "        return np.nan\n",
    "\n",
    "    res = cv2.matchTemplate(end, label, cv2.TM_CCOEFF_NORMED)\n",
    "    _, max_val, _, _ = cv2.minMaxLoc(res)\n",
    "    return max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m     label_url = row[\u001b[33m'\u001b[39m\u001b[33mlabel_image_url\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      4\u001b[39m     end_url = row[\u001b[33m'\u001b[39m\u001b[33mmatched_end_image_url\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     score = \u001b[43mcompute_template_match_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     scores.append(score)\n\u001b[32m      8\u001b[39m merged_df[\u001b[33m'\u001b[39m\u001b[33mopencv_template_score\u001b[39m\u001b[33m'\u001b[39m] = scores\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mcompute_template_match_score\u001b[39m\u001b[34m(label_url, end_url)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_template_match_score\u001b[39m(label_url, end_url):\n\u001b[32m     18\u001b[39m     label = load_image_from_url(label_url)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     end = \u001b[43mload_image_from_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m end \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     22\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m np.nan\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mload_image_from_url\u001b[39m\u001b[34m(url)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_image_from_url\u001b[39m(url):\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m         response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m         response.raise_for_status()\n\u001b[32m     10\u001b[39m         img_array = np.asarray(\u001b[38;5;28mbytearray\u001b[39m(response.content), dtype=np.uint8)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Ml/myenv/lib/python3.12/site-packages/requests/api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Ml/myenv/lib/python3.12/site-packages/requests/api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Ml/myenv/lib/python3.12/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Ml/myenv/lib/python3.12/site-packages/requests/sessions.py:746\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    743\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    745\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[32m--> \u001b[39m\u001b[32m746\u001b[39m     \u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Ml/myenv/lib/python3.12/site-packages/requests/models.py:902\u001b[39m, in \u001b[36mResponse.content\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    900\u001b[39m         \u001b[38;5;28mself\u001b[39m._content = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    901\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m902\u001b[39m         \u001b[38;5;28mself\u001b[39m._content = \u001b[33;43mb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    904\u001b[39m \u001b[38;5;28mself\u001b[39m._content_consumed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    905\u001b[39m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[32m    906\u001b[39m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Ml/myenv/lib/python3.12/site-packages/requests/models.py:820\u001b[39m, in \u001b[36mResponse.iter_content.<locals>.generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.raw, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw.stream(chunk_size, decode_content=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    822\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Ml/myenv/lib/python3.12/site-packages/urllib3/response.py:1066\u001b[39m, in \u001b[36mHTTPResponse.stream\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1064\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1065\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m._fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1066\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1068\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[32m   1069\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Ml/myenv/lib/python3.12/site-packages/urllib3/response.py:955\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt, decode_content, cache_content)\u001b[39m\n\u001b[32m    952\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) >= amt:\n\u001b[32m    953\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decoded_buffer.get(amt)\n\u001b[32m--> \u001b[39m\u001b[32m955\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    957\u001b[39m flush_decoder = amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[32m    959\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Ml/myenv/lib/python3.12/site-packages/urllib3/response.py:879\u001b[39m, in \u001b[36mHTTPResponse._raw_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    876\u001b[39m fp_closed = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._fp, \u001b[33m\"\u001b[39m\u001b[33mclosed\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    878\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._error_catcher():\n\u001b[32m--> \u001b[39m\u001b[32m879\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[32m    882\u001b[39m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    887\u001b[39m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[32m    888\u001b[39m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[32m    889\u001b[39m         \u001b[38;5;28mself\u001b[39m._fp.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Ml/myenv/lib/python3.12/site-packages/urllib3/response.py:862\u001b[39m, in \u001b[36mHTTPResponse._fp_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    859\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1()\n\u001b[32m    860\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    861\u001b[39m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m862\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:472\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    469\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt > \u001b[38;5;28mself\u001b[39m.length:\n\u001b[32m    470\u001b[39m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[32m    471\u001b[39m     amt = \u001b[38;5;28mself\u001b[39m.length\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m s = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[32m    474\u001b[39m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[32m    475\u001b[39m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[32m    476\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_conn()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/socket.py:707\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    708\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    709\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1249\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1245\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1246\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1247\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1248\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1249\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1250\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1105\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1103\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1106\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1107\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for idx, row in merged_df.iterrows():\n",
    "    label_url = row['label_image_url']\n",
    "    end_url = row['matched_end_image_url']\n",
    "    score = compute_template_match_score(label_url, end_url)\n",
    "    scores.append(score)\n",
    "\n",
    "merged_df['opencv_template_score'] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"mapped_with_opencv_score.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… OpenCV template matching completed for 100 rows!\n",
      "                                     label_image_url  \\\n",
      "0  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "1  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "2  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "3  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "4  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "\n",
      "                               matched_end_image_url  opencv_template_score  \n",
      "0  https://dtexg3-images.s3.ap-southeast-2.amazon...               0.216641  \n",
      "1  https://dtexg3-images.s3.ap-southeast-2.amazon...               0.246030  \n",
      "2  https://dtexg3-images.s3.ap-southeast-2.amazon...               0.186976  \n",
      "3  https://dtexg3-images.s3.ap-southeast-2.amazon...               0.150709  \n",
      "4  https://dtexg3-images.s3.ap-southeast-2.amazon...               0.185925  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l6/jvk_psqj1mz2tbsrq4j601_w0000gn/T/ipykernel_48673/313823909.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['opencv_template_score'] = scores\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "merged_df = pd.read_csv(\"merged_dashboard_data.csv\")\n",
    "\n",
    "# Function to load image from URL\n",
    "def load_image_from_url(url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        img_array = np.asarray(bytearray(response.content), dtype=np.uint8)\n",
    "        img = cv2.imdecode(img_array, cv2.IMREAD_GRAYSCALE)\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to load image from URL: {url} | Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to compute template match score\n",
    "def compute_template_match_score(label_url, end_url):\n",
    "    label = load_image_from_url(label_url)\n",
    "    end = load_image_from_url(end_url)\n",
    "    \n",
    "    if label is None or end is None:\n",
    "        return np.nan\n",
    "\n",
    "    if label.shape[0] > end.shape[0] or label.shape[1] > end.shape[1]:\n",
    "        return np.nan\n",
    "\n",
    "    res = cv2.matchTemplate(end, label, cv2.TM_CCOEFF_NORMED)\n",
    "    _, max_val, _, _ = cv2.minMaxLoc(res)\n",
    "    return max_val\n",
    "\n",
    "# Limit to first 100 rows for testing\n",
    "test_df = merged_df.head(100)\n",
    "\n",
    "# Compute scores\n",
    "scores = []\n",
    "for idx, row in test_df.iterrows():\n",
    "    label_url = row['label_image_url']\n",
    "    end_url = row['matched_end_image_url']\n",
    "    score = compute_template_match_score(label_url, end_url)\n",
    "    scores.append(score)\n",
    "\n",
    "test_df['opencv_template_score'] = scores\n",
    "\n",
    "# Save results\n",
    "test_df.to_csv(\"mapped_with_opencv_score_test100.csv\", index=False)\n",
    "\n",
    "print(\"âœ… OpenCV template matching completed for 100 rows!\")\n",
    "print(test_df[['label_image_url', 'matched_end_image_url', 'opencv_template_score']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Optimized template matching done for 100 rows!\n",
      "                                     label_image_url  \\\n",
      "0  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "1  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "2  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "3  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "4  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "\n",
      "                               matched_end_image_url  opencv_template_score  \n",
      "0  https://dtexg3-images.s3.ap-southeast-2.amazon...               0.230662  \n",
      "1  https://dtexg3-images.s3.ap-southeast-2.amazon...               0.278055  \n",
      "2  https://dtexg3-images.s3.ap-southeast-2.amazon...               0.212339  \n",
      "3  https://dtexg3-images.s3.ap-southeast-2.amazon...               0.220275  \n",
      "4  https://dtexg3-images.s3.ap-southeast-2.amazon...               0.168847  \n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Load your mapped data (limit to 100 rows for testing)\n",
    "merged_df = pd.read_csv(\"merged_dashboard_data.csv\").head(100)\n",
    "\n",
    "# Load image from URL\n",
    "def load_image_from_url(url, color=cv2.IMREAD_GRAYSCALE):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=20)\n",
    "        response.raise_for_status()\n",
    "        img_array = np.asarray(bytearray(response.content), dtype=np.uint8)\n",
    "        img = cv2.imdecode(img_array, color)\n",
    "        return img\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Compute template match score\n",
    "def compute_template_match(row, max_template_ratio=0.5):\n",
    "    label_url = row['label_image_url']\n",
    "    end_url = row['matched_end_image_url']\n",
    "    label = load_image_from_url(label_url)\n",
    "    end = load_image_from_url(end_url)\n",
    "    \n",
    "    if label is None or end is None:\n",
    "        return np.nan\n",
    "\n",
    "    # Resize label if it's too large compared to end\n",
    "    h_ratio = label.shape[0] / end.shape[0]\n",
    "    w_ratio = label.shape[1] / end.shape[1]\n",
    "    if max(h_ratio, w_ratio) > max_template_ratio:\n",
    "        scale = max_template_ratio / max(h_ratio, w_ratio)\n",
    "        label = cv2.resize(label, (int(label.shape[1]*scale), int(label.shape[0]*scale)))\n",
    "\n",
    "    try:\n",
    "        res = cv2.matchTemplate(end, label, cv2.TM_CCOEFF_NORMED)\n",
    "        _, max_val, _, _ = cv2.minMaxLoc(res)\n",
    "        return max_val\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# merged_df =merged_df.head(50)\n",
    "# Run in parallel (up to 8 threads, adjust for your system)\n",
    "with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "    scores = list(executor.map(compute_template_match, [row for _, row in merged_df.iterrows()]))\n",
    "\n",
    "merged_df['opencv_template_score'] = scores\n",
    "\n",
    "# Save results\n",
    "merged_df.to_csv(\"mapped_with_opencv_score_100.csv\", index=False)\n",
    "print(\"âœ… Optimized template matching done for 100 rows!\")\n",
    "print(merged_df[['label_image_url', 'matched_end_image_url', 'opencv_template_score']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l6/jvk_psqj1mz2tbsrq4j601_w0000gn/T/ipykernel_48673/3356458676.py:13: UserWarning: Parsing dates in %d/%m/%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df = pd.read_csv(report_path, parse_dates=['date_captured'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Loading report data...\n",
      "âœ… Report loaded with 1112 rows.\n",
      "ðŸ”¹ Splitting labels and ends...\n",
      "âœ… Found 606 label images and 506 end images.\n",
      "ðŸ”¹ Matching labels to ends by visit and time proximity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 606/606 [00:00<00:00, 1443.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Matching complete.\n",
      "ðŸ”¹ Running OpenCV template matching for validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 241/606 [05:14<10:55,  1.80s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 242/606 [05:15<09:41,  1.60s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 243/606 [05:16<08:22,  1.38s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 244/606 [05:17<07:44,  1.28s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 245/606 [05:18<07:24,  1.23s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 477/606 [11:29<02:55,  1.36s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 478/606 [11:31<02:55,  1.37s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 479/606 [11:32<02:59,  1.41s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 480/606 [11:34<02:50,  1.35s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 481/606 [11:35<02:57,  1.42s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 482/606 [11:36<02:42,  1.31s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 483/606 [11:37<02:33,  1.25s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 484/606 [11:39<02:37,  1.29s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 485/606 [11:40<02:42,  1.34s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 486/606 [11:42<02:45,  1.38s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 487/606 [11:43<02:52,  1.45s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 488/606 [11:44<02:40,  1.36s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 489/606 [11:46<02:34,  1.32s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 490/606 [11:47<02:33,  1.32s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 491/606 [11:49<03:00,  1.57s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 492/606 [11:50<02:54,  1.53s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 493/606 [11:53<03:14,  1.72s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 494/606 [11:54<03:10,  1.70s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 495/606 [11:56<02:52,  1.56s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 496/606 [11:57<02:44,  1.50s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 497/606 [11:58<02:26,  1.34s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 498/606 [11:59<02:15,  1.25s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 499/606 [12:00<02:11,  1.23s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 500/606 [12:01<02:08,  1.21s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 501/606 [12:02<02:05,  1.20s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 502/606 [12:04<02:02,  1.18s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 503/606 [12:05<01:56,  1.14s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 504/606 [12:06<01:50,  1.08s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 505/606 [12:07<01:49,  1.09s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 506/606 [12:08<01:49,  1.09s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 507/606 [12:09<01:48,  1.09s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 508/606 [12:10<01:49,  1.12s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 509/606 [12:11<01:54,  1.18s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 510/606 [12:13<01:56,  1.21s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 511/606 [12:14<01:51,  1.17s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 512/606 [12:15<01:48,  1.15s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 513/606 [12:16<01:42,  1.10s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 514/606 [12:17<01:39,  1.08s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 515/606 [12:18<01:37,  1.08s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 516/606 [12:19<01:36,  1.07s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 517/606 [12:20<01:33,  1.05s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 518/606 [12:21<01:32,  1.05s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 519/606 [12:22<01:32,  1.07s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 520/606 [12:23<01:30,  1.05s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 521/606 [12:24<01:30,  1.06s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 522/606 [12:25<01:29,  1.06s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 523/606 [12:26<01:27,  1.05s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 524/606 [12:27<01:18,  1.05it/s]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 525/606 [12:28<01:19,  1.02it/s]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 526/606 [12:29<01:19,  1.00it/s]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 527/606 [12:30<01:27,  1.10s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 528/606 [12:32<01:24,  1.09s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 529/606 [12:33<01:30,  1.17s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 530/606 [12:34<01:29,  1.18s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 531/606 [12:35<01:27,  1.17s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 532/606 [12:36<01:28,  1.20s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 533/606 [12:38<01:24,  1.16s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 534/606 [12:39<01:21,  1.13s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 535/606 [12:40<01:18,  1.11s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 536/606 [12:41<01:19,  1.13s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 537/606 [12:42<01:23,  1.21s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 538/606 [12:43<01:22,  1.21s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 539/606 [12:45<01:21,  1.22s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 540/606 [12:46<01:17,  1.18s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 541/606 [12:47<01:15,  1.16s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 542/606 [12:48<01:16,  1.19s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 543/606 [12:49<01:12,  1.16s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 544/606 [12:51<01:13,  1.18s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 545/606 [12:52<01:08,  1.13s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 546/606 [12:53<01:05,  1.09s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 547/606 [12:54<01:07,  1.14s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 548/606 [12:55<01:08,  1.19s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 549/606 [12:56<01:04,  1.13s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 550/606 [12:57<01:05,  1.17s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 551/606 [12:59<01:12,  1.33s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 552/606 [13:01<01:21,  1.52s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 553/606 [13:03<01:33,  1.76s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 554/606 [13:05<01:37,  1.88s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 555/606 [13:07<01:31,  1.80s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 556/606 [13:08<01:23,  1.68s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 557/606 [13:10<01:15,  1.53s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 558/606 [13:11<01:13,  1.52s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 559/606 [13:12<01:05,  1.39s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 560/606 [13:13<01:00,  1.31s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 561/606 [13:14<00:56,  1.25s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 562/606 [13:16<00:55,  1.25s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 563/606 [13:17<00:55,  1.29s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 564/606 [13:18<00:55,  1.31s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 565/606 [13:20<00:52,  1.28s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 566/606 [13:21<00:52,  1.32s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 567/606 [13:22<00:48,  1.25s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 568/606 [13:23<00:45,  1.19s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 569/606 [13:25<00:46,  1.25s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 570/606 [13:26<00:41,  1.16s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 571/606 [13:27<00:39,  1.14s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 572/606 [13:28<00:39,  1.16s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 573/606 [13:29<00:37,  1.13s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 574/606 [13:30<00:36,  1.16s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 575/606 [13:32<00:38,  1.23s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 576/606 [13:33<00:35,  1.17s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 577/606 [13:34<00:35,  1.21s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 578/606 [13:35<00:33,  1.19s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 579/606 [13:36<00:30,  1.12s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 580/606 [13:37<00:27,  1.07s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 581/606 [13:38<00:26,  1.07s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 582/606 [13:39<00:26,  1.10s/it]Invalid SOS parameters for sequential JPEG\n",
      "Matching: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 606/606 [14:25<00:00,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… OpenCV template matching complete.\n",
      "ðŸ”¹ Computing final confidence scores...\n",
      "âœ… Confidence scoring complete.\n",
      "âœ… Final mapping with confidence saved to: final_label_end_mapping_with_confidence.csv\n",
      "\n",
      "ðŸ” Sample Results:\n",
      "                                       label_image_url  \\\n",
      "252  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "253  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "254  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "255  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "256  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "\n",
      "                                 matched_end_image_url  final_confidence  \\\n",
      "252  https://dtexg3-images.s3.ap-southeast-2.amazon...          0.579565   \n",
      "253  https://dtexg3-images.s3.ap-southeast-2.amazon...          0.602917   \n",
      "254  https://dtexg3-images.s3.ap-southeast-2.amazon...          0.672557   \n",
      "255  https://dtexg3-images.s3.ap-southeast-2.amazon...          0.509396   \n",
      "256  https://dtexg3-images.s3.ap-southeast-2.amazon...          0.552194   \n",
      "\n",
      "    confidence_flag  \n",
      "252           âŒ Low  \n",
      "253       âš ï¸ Review  \n",
      "254       âš ï¸ Review  \n",
      "255           âŒ Low  \n",
      "256           âŒ Low  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ================================\n",
    "# 1ï¸âƒ£ Load and Prepare Data\n",
    "# ================================\n",
    "print(\"ðŸ”¹ Loading report data...\")\n",
    "report_path = \"20250514-report.csv\"\n",
    "df = pd.read_csv(report_path, parse_dates=['date_captured'])\n",
    "df =df[df['end_location'] == \" Off Location \"]\n",
    "df.columns = df.columns.str.strip().str.replace('\"', '')\n",
    "\n",
    "print(f\"âœ… Report loaded with {len(df)} rows.\")\n",
    "\n",
    "# ================================\n",
    "# 2ï¸âƒ£ Split Labels and Ends\n",
    "# ================================\n",
    "print(\"ðŸ”¹ Splitting labels and ends...\")\n",
    "labels_df = df[df['sku'] != '-'].copy()\n",
    "ends_df = df[df['sku'] == '-'].copy()\n",
    "\n",
    "print(f\"âœ… Found {len(labels_df)} label images and {len(ends_df)} end images.\")\n",
    "\n",
    "# ================================\n",
    "# 3ï¸âƒ£ Match Labels to Ends by Visit + Timestamp\n",
    "# ================================\n",
    "print(\"ðŸ”¹ Matching labels to ends by visit and time proximity...\")\n",
    "\n",
    "def find_best_end(label_row, ends_df, time_window='5min'):\n",
    "    visit_id = label_row['visit_id']\n",
    "    label_time = label_row['date_captured']\n",
    "    candidates = ends_df[ends_df['visit_id'] == visit_id].copy()\n",
    "    candidates = candidates[\n",
    "        (candidates['date_captured'] >= label_time - pd.Timedelta(time_window)) &\n",
    "        (candidates['date_captured'] <= label_time + pd.Timedelta(time_window))\n",
    "    ]\n",
    "    if candidates.empty:\n",
    "        fallback = ends_df[ends_df['visit_id'] == visit_id].sort_values('date_captured').head(1)\n",
    "        if not fallback.empty:\n",
    "            return fallback['end_image_url'].values[0], abs((label_time - fallback['date_captured'].values[0]).astype('timedelta64[m]').astype(int))\n",
    "        else:\n",
    "            return np.nan, np.nan\n",
    "    else:\n",
    "        candidates['time_diff'] = abs(candidates['date_captured'] - label_time).dt.total_seconds() / 60\n",
    "        best_match = candidates.sort_values('time_diff').iloc[0]\n",
    "        return best_match['end_image_url'], best_match['time_diff']\n",
    "\n",
    "tqdm.pandas(desc=\"Matching\")\n",
    "labels_df[['matched_end_image_url', 'timestamp_diff_min']] = labels_df.progress_apply(\n",
    "    lambda row: pd.Series(find_best_end(row, ends_df)), axis=1\n",
    ")\n",
    "\n",
    "print(\"âœ… Matching complete.\")\n",
    "\n",
    "# ================================\n",
    "# 4ï¸âƒ£ OpenCV Template Matching Validation\n",
    "# ================================\n",
    "print(\"ðŸ”¹ Running OpenCV template matching for validation...\")\n",
    "\n",
    "def load_image_from_url(url, color=cv2.IMREAD_GRAYSCALE):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)\n",
    "        response.raise_for_status()\n",
    "        img_array = np.asarray(bytearray(response.content), dtype=np.uint8)\n",
    "        return cv2.imdecode(img_array, color)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def compute_template_match(row, max_template_ratio=0.5):\n",
    "    label_url = row['label_image_url']\n",
    "    end_url = row['matched_end_image_url']\n",
    "    label = load_image_from_url(label_url)\n",
    "    end = load_image_from_url(end_url)\n",
    "    \n",
    "    if label is None or end is None:\n",
    "        return np.nan\n",
    "\n",
    "    h_ratio = label.shape[0] / end.shape[0]\n",
    "    w_ratio = label.shape[1] / end.shape[1]\n",
    "    if max(h_ratio, w_ratio) > max_template_ratio:\n",
    "        scale = max_template_ratio / max(h_ratio, w_ratio)\n",
    "        label = cv2.resize(label, (int(label.shape[1]*scale), int(label.shape[0]*scale)))\n",
    "\n",
    "    try:\n",
    "        res = cv2.matchTemplate(end, label, cv2.TM_CCOEFF_NORMED)\n",
    "        _, max_val, _, _ = cv2.minMaxLoc(res)\n",
    "        return max_val\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "labels_df['opencv_template_score'] = labels_df.progress_apply(compute_template_match, axis=1)\n",
    "\n",
    "print(\"âœ… OpenCV template matching complete.\")\n",
    "\n",
    "# ================================\n",
    "# 5ï¸âƒ£ Compute Confidence Scores\n",
    "# ================================\n",
    "print(\"ðŸ”¹ Computing final confidence scores...\")\n",
    "\n",
    "def brand_score(label_brand, product_name):\n",
    "    if pd.isna(label_brand) or pd.isna(product_name):\n",
    "        return 0.0\n",
    "    return 1.0 if label_brand.lower() in product_name.lower() else 0.5\n",
    "\n",
    "labels_df['brand_confidence'] = labels_df.apply(\n",
    "    lambda row: brand_score(row['brand'], row['product_name']), axis=1\n",
    ")\n",
    "\n",
    "alpha, beta, gamma = 0.5, 0.3, 0.2\n",
    "labels_df['final_confidence'] = (\n",
    "    alpha * labels_df['opencv_template_score'].fillna(0) +\n",
    "    beta * labels_df['timestamp_diff_min'].apply(lambda x: 1.0 if x <= 2 else 0.8 if x <=5 else 0.5).fillna(0) +\n",
    "    gamma * labels_df['brand_confidence']\n",
    ")\n",
    "\n",
    "labels_df['confidence_flag'] = labels_df['final_confidence'].apply(\n",
    "    lambda x: 'âœ… High' if x >= 0.85 else ('âš ï¸ Review' if x >= 0.6 else 'âŒ Low')\n",
    ")\n",
    "\n",
    "print(\"âœ… Confidence scoring complete.\")\n",
    "\n",
    "# ================================\n",
    "# 6ï¸âƒ£ Save Final Output\n",
    "# ================================\n",
    "final_output_path = \"final_label_end_mapping_with_confidence.csv\"\n",
    "labels_df.to_csv(final_output_path, index=False)\n",
    "print(f\"âœ… Final mapping with confidence saved to: {final_output_path}\")\n",
    "\n",
    "# ================================\n",
    "# 7ï¸âƒ£ Sample Output\n",
    "# ================================\n",
    "print(\"\\nðŸ” Sample Results:\")\n",
    "print(labels_df[['label_image_url', 'matched_end_image_url', 'final_confidence', 'confidence_flag']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_csv('20250514-report.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l6/jvk_psqj1mz2tbsrq4j601_w0000gn/T/ipykernel_48673/4283321698.py:1: UserWarning: Parsing dates in %d/%m/%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df['date_captured'] = pd.to_datetime(df['date_captured']).dt.strftime('%Y-%m-%d %H:%M:%S.%f').str[:-3]\n"
     ]
    }
   ],
   "source": [
    "df['date_captured'] = pd.to_datetime(df['date_captured']).dt.strftime('%Y-%m-%d %H:%M:%S.%f').str[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2025-05-14 14:28:00.000\n",
       "1       2025-05-14 14:28:00.000\n",
       "2       2025-05-14 14:29:00.000\n",
       "3       2025-05-14 14:30:00.000\n",
       "4       2025-05-14 14:29:00.000\n",
       "                 ...           \n",
       "4396    2025-05-16 09:44:00.000\n",
       "4397    2025-05-16 09:44:00.000\n",
       "4398    2025-05-16 09:43:00.000\n",
       "4399    2025-05-16 09:44:00.000\n",
       "4400    2025-05-16 09:44:00.000\n",
       "Name: date_captured, Length: 4401, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['date_captured']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l6/jvk_psqj1mz2tbsrq4j601_w0000gn/T/ipykernel_58470/3708176220.py:10: UserWarning: Parsing dates in %d/%m/%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df = pd.read_csv(\"20250514-report.csv\", parse_dates=['date_captured'])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from tqdm import tqdm\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# Load Data\n",
    "df = pd.read_csv(\"20250514-report.csv\", parse_dates=['date_captured'])\n",
    "df.columns = df.columns.str.strip().str.replace('\"', '')\n",
    "\n",
    "# Filter for Off Location\n",
    "df = df[df['end_location'].str.lower().str.contains(\"off\", na=False)].copy()\n",
    "\n",
    "df =df[(df['store_type']== 'Coles') & (df['store_suburb'].str.lower().str.contains(\"croydon\",na=False)) ]\n",
    "\n",
    "\n",
    "# Split into Ends (sku == '-') and Labels (sku != '-')\n",
    "ends_df = df[df['sku'] == '-'].copy()\n",
    "labels_df = df[df['sku'] != '-'].copy()\n",
    "\n",
    "\n",
    "\n",
    "# # print(f\"âœ… {len(labels_df)} labels | {len(ends_df)} ends filtered for Off Location.\")\n",
    "\n",
    "# # Image Loader\n",
    "# def load_image_from_url(url, color=cv2.IMREAD_GRAYSCALE):\n",
    "#     try:\n",
    "#         response = requests.get(url, timeout=10)\n",
    "#         response.raise_for_status()\n",
    "#         img_array = np.asarray(bytearray(response.content), dtype=np.uint8)\n",
    "#         return cv2.imdecode(img_array, color)\n",
    "#     except:\n",
    "#         return None\n",
    "\n",
    "# # Visual Matching Function\n",
    "# def match_label_to_filtered_ends(label_row, ends_df):\n",
    "#     label_time = pd.to_datetime(label_row['date_captured'], errors='coerce')\n",
    "#     label_end_url = label_row['end_image_url']\n",
    "#     label_img = load_image_from_url(label_end_url)\n",
    "#     if label_img is None:\n",
    "#         return np.nan, np.nan, 'âŒ Label Image Missing'\n",
    "\n",
    "#     # Filter Ends by same visit_id, store_type, end_location_number, and same date\n",
    "#     candidates = ends_df[\n",
    "#         (ends_df['visit_id'] == label_row['visit_id']) &\n",
    "#         (ends_df['store_type'] == label_row['store_type']) &\n",
    "#         (ends_df['end_location_number'] == label_row['end_location_number']) &\n",
    "#         (ends_df['date_captured'].dt.date == label_time.date())\n",
    "#     ]\n",
    "\n",
    "#     if candidates.empty:\n",
    "#         return np.nan, np.nan, 'âŒ No Ends Found (Filtered)'\n",
    "\n",
    "#     best_score = -1\n",
    "#     best_end_url = None\n",
    "\n",
    "#     for _, end_row in candidates.iterrows():\n",
    "#         end_img = load_image_from_url(end_row['end_image_url'])\n",
    "#         if end_img is None:\n",
    "#             continue\n",
    "#         try:\n",
    "#             label_resized = cv2.resize(label_img, (500, 500))\n",
    "#             end_resized = cv2.resize(end_img, (500, 500))\n",
    "#             score, _ = ssim(label_resized, end_resized, full=True)\n",
    "#         except:\n",
    "#             score = np.nan\n",
    "\n",
    "#         if score > best_score:\n",
    "#             best_score = score\n",
    "#             best_end_url = end_row['end_image_url']\n",
    "\n",
    "#     if best_end_url:\n",
    "#         return best_end_url, best_score, 'âœ… Best SSIM Match'\n",
    "#     else:\n",
    "#         return np.nan, np.nan, 'âŒ No Visual Match'\n",
    "# # Apply Matching\n",
    "# tqdm.pandas(desc=\"Matching Labels to Ends (SSIM)\")\n",
    "# labels_df[['matched_end_image_url', 'ssim_score', 'match_type']] = labels_df.progress_apply(\n",
    "#     lambda row: pd.Series(match_label_to_filtered_ends(row, ends_df)), axis=1\n",
    "# )\n",
    "\n",
    "# # Save Results\n",
    "# labels_df.to_csv(\"off_location_visual_match_ssim.csv\", index=False)\n",
    "# print(\"âœ… Visual matching (SSIM) complete. Output saved as 'off_location_visual_match_ssim.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visit_id</th>\n",
       "      <th>visit_created</th>\n",
       "      <th>date_captured</th>\n",
       "      <th>end_image_url</th>\n",
       "      <th>label_image_url</th>\n",
       "      <th>store_type</th>\n",
       "      <th>store_type_id</th>\n",
       "      <th>store_suburb</th>\n",
       "      <th>store_postcode</th>\n",
       "      <th>...</th>\n",
       "      <th>label_type</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_name</th>\n",
       "      <th>pack_size</th>\n",
       "      <th>current_price</th>\n",
       "      <th>was_price</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>savings</th>\n",
       "      <th>multibuy_unit</th>\n",
       "      <th>multibuy_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>lblID-1195330</td>\n",
       "      <td>352670</td>\n",
       "      <td>14/5/2025</td>\n",
       "      <td>2025-05-14 14:38:00</td>\n",
       "      <td>https://dtexg3-images.s3.ap-southeast-2.amazon...</td>\n",
       "      <td>https://dtexg3-images.s3.ap-southeast-2.amazon...</td>\n",
       "      <td>Coles</td>\n",
       "      <td>15</td>\n",
       "      <td>Croydon</td>\n",
       "      <td>3136</td>\n",
       "      <td>...</td>\n",
       "      <td>30%_off</td>\n",
       "      <td>OREO</td>\n",
       "      <td>OREO PASCALL MARSHMALLOWS SLUG</td>\n",
       "      <td>131G</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>lblID-1195392</td>\n",
       "      <td>352670</td>\n",
       "      <td>14/5/2025</td>\n",
       "      <td>2025-05-14 14:35:00</td>\n",
       "      <td>https://dtexg3-images.s3.ap-southeast-2.amazon...</td>\n",
       "      <td>https://dtexg3-images.s3.ap-southeast-2.amazon...</td>\n",
       "      <td>Coles</td>\n",
       "      <td>15</td>\n",
       "      <td>Croydon</td>\n",
       "      <td>3136</td>\n",
       "      <td>...</td>\n",
       "      <td>30%_off</td>\n",
       "      <td>VICKS</td>\n",
       "      <td>VICKS VAPOUR SHOWER 5PK</td>\n",
       "      <td>5PACK</td>\n",
       "      <td>10.5</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>lblID-1195388</td>\n",
       "      <td>352670</td>\n",
       "      <td>14/5/2025</td>\n",
       "      <td>2025-05-14 14:42:00</td>\n",
       "      <td>https://dtexg3-images.s3.ap-southeast-2.amazon...</td>\n",
       "      <td>https://dtexg3-images.s3.ap-southeast-2.amazon...</td>\n",
       "      <td>Coles</td>\n",
       "      <td>15</td>\n",
       "      <td>Croydon</td>\n",
       "      <td>3136</td>\n",
       "      <td>...</td>\n",
       "      <td>half_price</td>\n",
       "      <td>DARRELL LEA</td>\n",
       "      <td>DARRELL LEA MILK CHOCOLATE LOVE HEART</td>\n",
       "      <td>100G</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>lblID-1195386</td>\n",
       "      <td>352670</td>\n",
       "      <td>14/5/2025</td>\n",
       "      <td>2025-05-14 14:35:00</td>\n",
       "      <td>https://dtexg3-images.s3.ap-southeast-2.amazon...</td>\n",
       "      <td>https://dtexg3-images.s3.ap-southeast-2.amazon...</td>\n",
       "      <td>Coles</td>\n",
       "      <td>15</td>\n",
       "      <td>Croydon</td>\n",
       "      <td>3136</td>\n",
       "      <td>...</td>\n",
       "      <td>half_price</td>\n",
       "      <td>BLACKMORES</td>\n",
       "      <td>LYP-SINE COLD SORE RELIEF TABLETS</td>\n",
       "      <td>30 PACK</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>23.33</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>lblID-1195385</td>\n",
       "      <td>352670</td>\n",
       "      <td>14/5/2025</td>\n",
       "      <td>2025-05-14 14:40:00</td>\n",
       "      <td>https://dtexg3-images.s3.ap-southeast-2.amazon...</td>\n",
       "      <td>https://dtexg3-images.s3.ap-southeast-2.amazon...</td>\n",
       "      <td>Coles</td>\n",
       "      <td>15</td>\n",
       "      <td>Croydon</td>\n",
       "      <td>3136</td>\n",
       "      <td>...</td>\n",
       "      <td>special_multibuy</td>\n",
       "      <td>RED BULL</td>\n",
       "      <td>SUGAR FREE ENERGY DRINK SINGLE CAN</td>\n",
       "      <td>250ML</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  visit_id visit_created       date_captured  \\\n",
       "252  lblID-1195330    352670     14/5/2025 2025-05-14 14:38:00   \n",
       "253  lblID-1195392    352670     14/5/2025 2025-05-14 14:35:00   \n",
       "254  lblID-1195388    352670     14/5/2025 2025-05-14 14:42:00   \n",
       "255  lblID-1195386    352670     14/5/2025 2025-05-14 14:35:00   \n",
       "256  lblID-1195385    352670     14/5/2025 2025-05-14 14:40:00   \n",
       "\n",
       "                                         end_image_url  \\\n",
       "252  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
       "253  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
       "254  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
       "255  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
       "256  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
       "\n",
       "                                       label_image_url store_type  \\\n",
       "252  https://dtexg3-images.s3.ap-southeast-2.amazon...      Coles   \n",
       "253  https://dtexg3-images.s3.ap-southeast-2.amazon...      Coles   \n",
       "254  https://dtexg3-images.s3.ap-southeast-2.amazon...      Coles   \n",
       "255  https://dtexg3-images.s3.ap-southeast-2.amazon...      Coles   \n",
       "256  https://dtexg3-images.s3.ap-southeast-2.amazon...      Coles   \n",
       "\n",
       "     store_type_id store_suburb  store_postcode  ...        label_type  \\\n",
       "252             15      Croydon            3136  ...           30%_off   \n",
       "253             15      Croydon            3136  ...           30%_off   \n",
       "254             15      Croydon            3136  ...        half_price   \n",
       "255             15      Croydon            3136  ...        half_price   \n",
       "256             15      Croydon            3136  ...  special_multibuy   \n",
       "\n",
       "           brand                           product_name pack_size  \\\n",
       "252         OREO         OREO PASCALL MARSHMALLOWS SLUG      131G   \n",
       "253        VICKS                VICKS VAPOUR SHOWER 5PK     5PACK   \n",
       "254  DARRELL LEA  DARRELL LEA MILK CHOCOLATE LOVE HEART      100G   \n",
       "255   BLACKMORES      LYP-SINE COLD SORE RELIEF TABLETS   30 PACK   \n",
       "256     RED BULL     SUGAR FREE ENERGY DRINK SINGLE CAN     250ML   \n",
       "\n",
       "    current_price was_price unit_price savings multibuy_unit multibuy_price  \n",
       "252             2         3          0       1             0              0  \n",
       "253          10.5        15          0     4.5             0              0  \n",
       "254           4.5         9        4.5     4.5             0              0  \n",
       "255             7        14      23.33       7             0              0  \n",
       "256          3.25         0       3.25       1             2            5.5  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can only compare identically-labeled Series objects",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m candidat_df = ends_df[((\u001b[43mlabels_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdate_captured\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mends_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdate_captured\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdate\u001b[49m))]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Ml/myenv/lib/python3.12/site-packages/pandas/core/ops/common.py:76\u001b[39m, in \u001b[36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     72\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m     74\u001b[39m other = item_from_zerodim(other)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Ml/myenv/lib/python3.12/site-packages/pandas/core/arraylike.py:40\u001b[39m, in \u001b[36mOpsMixin.__eq__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m__eq__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Ml/myenv/lib/python3.12/site-packages/pandas/core/series.py:6114\u001b[39m, in \u001b[36mSeries._cmp_method\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m   6111\u001b[39m res_name = ops.get_op_result_name(\u001b[38;5;28mself\u001b[39m, other)\n\u001b[32m   6113\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, Series) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._indexed_same(other):\n\u001b[32m-> \u001b[39m\u001b[32m6114\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCan only compare identically-labeled Series objects\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6116\u001b[39m lvalues = \u001b[38;5;28mself\u001b[39m._values\n\u001b[32m   6117\u001b[39m rvalues = extract_array(other, extract_numpy=\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mValueError\u001b[39m: Can only compare identically-labeled Series objects"
     ]
    }
   ],
   "source": [
    "candidat_df = ends_df[((labels_df['date_captured'].dt.date == ends_df['date_captured'].dt.date))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'visit_id', 'visit_created', 'date_captured', 'end_image_url',\n",
       "       'label_image_url', 'store_type', 'store_type_id', 'store_suburb',\n",
       "       'store_postcode', 'store_state', 'location_tag', 'end_location',\n",
       "       'end_location_number', 'sku', 'label_type', 'brand', 'product_name',\n",
       "       'pack_size', 'current_price', 'was_price', 'unit_price', 'savings',\n",
       "       'multibuy_unit', 'multibuy_price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'visit_id', 'visit_created', 'date_captured', 'end_image_url',\n",
       "       'label_image_url', 'store_type', 'store_type_id', 'store_suburb',\n",
       "       'store_postcode', 'store_state', 'location_tag', 'end_location',\n",
       "       'end_location_number', 'sku', 'label_type', 'brand', 'product_name',\n",
       "       'pack_size', 'current_price', 'was_price', 'unit_price', 'savings',\n",
       "       'multibuy_unit', 'multibuy_price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ends_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can only compare identically-labeled Series objects",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m candidates = labels_df[\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m         (\u001b[43mlabels_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mvisit_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mends_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mvisit_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m) &\n\u001b[32m      3\u001b[39m         (labels_df[\u001b[33m'\u001b[39m\u001b[33mstore_type\u001b[39m\u001b[33m'\u001b[39m] == ends_df[\u001b[33m'\u001b[39m\u001b[33mstore_type\u001b[39m\u001b[33m'\u001b[39m]) &\n\u001b[32m      4\u001b[39m         (labels_df[\u001b[33m'\u001b[39m\u001b[33mend_location_number\u001b[39m\u001b[33m'\u001b[39m] == ends_df[\u001b[33m'\u001b[39m\u001b[33mend_location_number\u001b[39m\u001b[33m'\u001b[39m]) &\n\u001b[32m      5\u001b[39m         (labels_df[\u001b[33m'\u001b[39m\u001b[33mdate_captured\u001b[39m\u001b[33m'\u001b[39m].dt.date == ends_df.date())\n\u001b[32m      6\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Ml/myenv/lib/python3.12/site-packages/pandas/core/ops/common.py:76\u001b[39m, in \u001b[36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     72\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m     74\u001b[39m other = item_from_zerodim(other)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Ml/myenv/lib/python3.12/site-packages/pandas/core/arraylike.py:40\u001b[39m, in \u001b[36mOpsMixin.__eq__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m__eq__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Ml/myenv/lib/python3.12/site-packages/pandas/core/series.py:6114\u001b[39m, in \u001b[36mSeries._cmp_method\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m   6111\u001b[39m res_name = ops.get_op_result_name(\u001b[38;5;28mself\u001b[39m, other)\n\u001b[32m   6113\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, Series) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._indexed_same(other):\n\u001b[32m-> \u001b[39m\u001b[32m6114\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCan only compare identically-labeled Series objects\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6116\u001b[39m lvalues = \u001b[38;5;28mself\u001b[39m._values\n\u001b[32m   6117\u001b[39m rvalues = extract_array(other, extract_numpy=\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mValueError\u001b[39m: Can only compare identically-labeled Series objects"
     ]
    }
   ],
   "source": [
    "candidates = labels_df[\n",
    "        (labels_df['visit_id'] == ends_df['visit_id']) &\n",
    "        (labels_df['store_type'] == ends_df['store_type']) &\n",
    "        (labels_df['end_location_number'] == ends_df['end_location_number']) &\n",
    "        (labels_df['date_captured'].dt.date == ends_df.date())\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Filtered 8 rows around 2025-05-14 16:44:00\n",
      "âœ… 4 Ends and 4 Labels in filtered data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l6/jvk_psqj1mz2tbsrq4j601_w0000gn/T/ipykernel_58470/498189584.py:4: UserWarning: Parsing dates in %d/%m/%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df = pd.read_csv(\"20250514-report.csv\", parse_dates=['date_captured'])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load Data\n",
    "df = pd.read_csv(\"20250514-report.csv\", parse_dates=['date_captured'])\n",
    "df.columns = df.columns.str.strip().str.replace('\"', '')\n",
    "\n",
    "# 1ï¸âƒ£ Filter by specific datetime (replace with your target)\n",
    "target_time = pd.Timestamp(\"2025-05-14 16:44:00\")\n",
    "\n",
    "\n",
    "# Filter: Keep rows within a small window (+/- 5 seconds)\n",
    "time_window = '5s'\n",
    "filtered_df = df[\n",
    "    (df['date_captured'] >= target_time - pd.Timedelta(time_window)) &\n",
    "    (df['date_captured'] <= target_time + pd.Timedelta(time_window))\n",
    "].copy()\n",
    "\n",
    "print(f\"âœ… Filtered {len(filtered_df)} rows around {target_time}\")\n",
    "\n",
    "# 2ï¸âƒ£ Split into Ends and Labels\n",
    "ends_df = filtered_df[filtered_df['sku'] == '-'].copy()\n",
    "labels_df = filtered_df[filtered_df['sku'] != '-'].copy()\n",
    "\n",
    "print(f\"âœ… {len(ends_df)} Ends and {len(labels_df)} Labels in filtered data.\")\n",
    "\n",
    "# 3ï¸âƒ£ Save for SSIM matching later (optional)\n",
    "# ends_df.to_csv(\"filtered_ends.csv\", index=False)\n",
    "# labels_df.to_csv(\"filtered_labels.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visit_id</th>\n",
       "      <th>visit_created</th>\n",
       "      <th>date_captured</th>\n",
       "      <th>end_image_url</th>\n",
       "      <th>label_image_url</th>\n",
       "      <th>store_type</th>\n",
       "      <th>store_type_id</th>\n",
       "      <th>store_suburb</th>\n",
       "      <th>store_postcode</th>\n",
       "      <th>...</th>\n",
       "      <th>label_type</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_name</th>\n",
       "      <th>pack_size</th>\n",
       "      <th>current_price</th>\n",
       "      <th>was_price</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>savings</th>\n",
       "      <th>multibuy_unit</th>\n",
       "      <th>multibuy_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>incID-813156</td>\n",
       "      <td>352779</td>\n",
       "      <td>14/5/2025</td>\n",
       "      <td>2025-05-14 16:44:00</td>\n",
       "      <td>https://dtexg3-images.s3.ap-southeast-2.amazon...</td>\n",
       "      <td>https://dtexg3-images.s3.ap-southeast-2.amazon...</td>\n",
       "      <td>Coles</td>\n",
       "      <td>15</td>\n",
       "      <td>Penrith</td>\n",
       "      <td>2750</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>incID-813160</td>\n",
       "      <td>352779</td>\n",
       "      <td>14/5/2025</td>\n",
       "      <td>2025-05-14 16:44:00</td>\n",
       "      <td>https://dtexg3-images.s3.ap-southeast-2.amazon...</td>\n",
       "      <td>https://dtexg3-images.s3.ap-southeast-2.amazon...</td>\n",
       "      <td>Coles</td>\n",
       "      <td>15</td>\n",
       "      <td>Penrith</td>\n",
       "      <td>2750</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>incID-813158</td>\n",
       "      <td>352779</td>\n",
       "      <td>14/5/2025</td>\n",
       "      <td>2025-05-14 16:44:00</td>\n",
       "      <td>https://dtexg3-images.s3.ap-southeast-2.amazon...</td>\n",
       "      <td>https://dtexg3-images.s3.ap-southeast-2.amazon...</td>\n",
       "      <td>Coles</td>\n",
       "      <td>15</td>\n",
       "      <td>Penrith</td>\n",
       "      <td>2750</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>incID-813154</td>\n",
       "      <td>352779</td>\n",
       "      <td>14/5/2025</td>\n",
       "      <td>2025-05-14 16:44:00</td>\n",
       "      <td>https://dtexg3-images.s3.ap-southeast-2.amazon...</td>\n",
       "      <td>-</td>\n",
       "      <td>Coles</td>\n",
       "      <td>15</td>\n",
       "      <td>Penrith</td>\n",
       "      <td>2750</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  visit_id visit_created       date_captured  \\\n",
       "710  incID-813156    352779     14/5/2025 2025-05-14 16:44:00   \n",
       "712  incID-813160    352779     14/5/2025 2025-05-14 16:44:00   \n",
       "713  incID-813158    352779     14/5/2025 2025-05-14 16:44:00   \n",
       "716  incID-813154    352779     14/5/2025 2025-05-14 16:44:00   \n",
       "\n",
       "                                         end_image_url  \\\n",
       "710  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
       "712  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
       "713  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
       "716  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
       "\n",
       "                                       label_image_url store_type  \\\n",
       "710  https://dtexg3-images.s3.ap-southeast-2.amazon...      Coles   \n",
       "712  https://dtexg3-images.s3.ap-southeast-2.amazon...      Coles   \n",
       "713  https://dtexg3-images.s3.ap-southeast-2.amazon...      Coles   \n",
       "716                                                  -      Coles   \n",
       "\n",
       "     store_type_id store_suburb  store_postcode  ... label_type brand  \\\n",
       "710             15      Penrith            2750  ...          -     -   \n",
       "712             15      Penrith            2750  ...          -     -   \n",
       "713             15      Penrith            2750  ...          -     -   \n",
       "716             15      Penrith            2750  ...          -     -   \n",
       "\n",
       "    product_name pack_size current_price was_price unit_price savings  \\\n",
       "710            -         -             -         -          -       -   \n",
       "712            -         -             -         -          -       -   \n",
       "713            -         -             -         -          -       -   \n",
       "716            -         -             -         -          -       -   \n",
       "\n",
       "    multibuy_unit multibuy_price  \n",
       "710             -              -  \n",
       "712             -              -  \n",
       "713             -              -  \n",
       "716             -              -  \n",
       "\n",
       "[4 rows x 25 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ends_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visit_id</th>\n",
       "      <th>visit_created</th>\n",
       "      <th>date_captured</th>\n",
       "      <th>end_image_url</th>\n",
       "      <th>label_image_url</th>\n",
       "      <th>store_type</th>\n",
       "      <th>store_type_id</th>\n",
       "      <th>store_suburb</th>\n",
       "      <th>store_postcode</th>\n",
       "      <th>...</th>\n",
       "      <th>label_type</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_name</th>\n",
       "      <th>pack_size</th>\n",
       "      <th>current_price</th>\n",
       "      <th>was_price</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>savings</th>\n",
       "      <th>multibuy_unit</th>\n",
       "      <th>multibuy_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>lblID-1196053</td>\n",
       "      <td>352779</td>\n",
       "      <td>14/5/2025</td>\n",
       "      <td>2025-05-14 16:44:00</td>\n",
       "      <td>https://dtexg3-images.s3.ap-southeast-2.amazon...</td>\n",
       "      <td>https://dtexg3-images.s3.ap-southeast-2.amazon...</td>\n",
       "      <td>Coles</td>\n",
       "      <td>15</td>\n",
       "      <td>Penrith</td>\n",
       "      <td>2750</td>\n",
       "      <td>...</td>\n",
       "      <td>special</td>\n",
       "      <td>HEINZ</td>\n",
       "      <td>BEANZ BAKED BEANS IN TOMATO SAUCE</td>\n",
       "      <td>555G</td>\n",
       "      <td>3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>lblID-1196054</td>\n",
       "      <td>352779</td>\n",
       "      <td>14/5/2025</td>\n",
       "      <td>2025-05-14 16:44:00</td>\n",
       "      <td>https://dtexg3-images.s3.ap-southeast-2.amazon...</td>\n",
       "      <td>https://dtexg3-images.s3.ap-southeast-2.amazon...</td>\n",
       "      <td>Coles</td>\n",
       "      <td>15</td>\n",
       "      <td>Penrith</td>\n",
       "      <td>2750</td>\n",
       "      <td>...</td>\n",
       "      <td>special</td>\n",
       "      <td>HEINZ</td>\n",
       "      <td>SPAGHETTI IN TOMATO SAUCE PASTA</td>\n",
       "      <td>535G</td>\n",
       "      <td>3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>lblID-1196056</td>\n",
       "      <td>352779</td>\n",
       "      <td>14/5/2025</td>\n",
       "      <td>2025-05-14 16:44:00</td>\n",
       "      <td>https://dtexg3-images.s3.ap-southeast-2.amazon...</td>\n",
       "      <td>https://dtexg3-images.s3.ap-southeast-2.amazon...</td>\n",
       "      <td>Coles</td>\n",
       "      <td>15</td>\n",
       "      <td>Penrith</td>\n",
       "      <td>2750</td>\n",
       "      <td>...</td>\n",
       "      <td>special_multibuy</td>\n",
       "      <td>CHEEZELS</td>\n",
       "      <td>6 PACK OR DORITOS CORN CHIPS</td>\n",
       "      <td>150G-170G</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>lblID-1196050</td>\n",
       "      <td>352779</td>\n",
       "      <td>14/5/2025</td>\n",
       "      <td>2025-05-14 16:44:00</td>\n",
       "      <td>https://dtexg3-images.s3.ap-southeast-2.amazon...</td>\n",
       "      <td>https://dtexg3-images.s3.ap-southeast-2.amazon...</td>\n",
       "      <td>Coles</td>\n",
       "      <td>15</td>\n",
       "      <td>Penrith</td>\n",
       "      <td>2750</td>\n",
       "      <td>...</td>\n",
       "      <td>special_multibuy</td>\n",
       "      <td>ARNOTTS</td>\n",
       "      <td>SHORTBREAD CREAM BISCUITS</td>\n",
       "      <td>250G</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  visit_id visit_created       date_captured  \\\n",
       "701  lblID-1196053    352779     14/5/2025 2025-05-14 16:44:00   \n",
       "706  lblID-1196054    352779     14/5/2025 2025-05-14 16:44:00   \n",
       "707  lblID-1196056    352779     14/5/2025 2025-05-14 16:44:00   \n",
       "708  lblID-1196050    352779     14/5/2025 2025-05-14 16:44:00   \n",
       "\n",
       "                                         end_image_url  \\\n",
       "701  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
       "706  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
       "707  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
       "708  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
       "\n",
       "                                       label_image_url store_type  \\\n",
       "701  https://dtexg3-images.s3.ap-southeast-2.amazon...      Coles   \n",
       "706  https://dtexg3-images.s3.ap-southeast-2.amazon...      Coles   \n",
       "707  https://dtexg3-images.s3.ap-southeast-2.amazon...      Coles   \n",
       "708  https://dtexg3-images.s3.ap-southeast-2.amazon...      Coles   \n",
       "\n",
       "     store_type_id store_suburb  store_postcode  ...        label_type  \\\n",
       "701             15      Penrith            2750  ...           special   \n",
       "706             15      Penrith            2750  ...           special   \n",
       "707             15      Penrith            2750  ...  special_multibuy   \n",
       "708             15      Penrith            2750  ...  special_multibuy   \n",
       "\n",
       "        brand                       product_name  pack_size current_price  \\\n",
       "701     HEINZ  BEANZ BAKED BEANS IN TOMATO SAUCE       555G             3   \n",
       "706     HEINZ    SPAGHETTI IN TOMATO SAUCE PASTA       535G             3   \n",
       "707  CHEEZELS       6 PACK OR DORITOS CORN CHIPS  150G-170G             4   \n",
       "708   ARNOTTS          SHORTBREAD CREAM BISCUITS       250G             4   \n",
       "\n",
       "    was_price unit_price savings multibuy_unit multibuy_price  \n",
       "701       3.8       0.54     0.8             0              0  \n",
       "706       3.8       0.56     0.8             0              0  \n",
       "707         0          0       1             2              7  \n",
       "708         0          0       2             2              6  \n",
       "\n",
       "[4 rows x 25 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l6/jvk_psqj1mz2tbsrq4j601_w0000gn/T/ipykernel_58666/1895616697.py:9: UserWarning: Parsing dates in %d/%m/%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df = pd.read_csv(\"20250514-report.csv\", parse_dates=['date_captured'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Filtered 8 rows for date 2025-05-14 16:44:00\n",
      "âœ… Saved 4 ends and 4 labels.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching Labels to Ends:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label https://dtexg3-images.s3.ap-southeast-2.amazonaws.com/mobile_uploads/20250514-164456-18WBXa_cc9c5d06-72be-49f1-a3ce-a005b450bf88_3_eoa_12568_-33.7508916_150.693301_android_34_11p03-01_b0_s0_false.jpg vs End https://dtexg3-images.s3.ap-southeast-2.amazonaws.com/mobile_uploads/20250514-164401-lgnixh_cc9c5d06-72be-49f1-a3ce-a005b450bf88_3_eoa_12568_-33.7508916_150.693301_android_34_11p03-01_b0_s0_true.jpg: SSIM = 0.3676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching Labels to Ends:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:06<00:06,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label https://dtexg3-images.s3.ap-southeast-2.amazonaws.com/mobile_uploads/20250514-164453-QcJwkL_cc9c5d06-72be-49f1-a3ce-a005b450bf88_3_eoa_12568_-33.7508916_150.693301_android_34_11p03-01_b0_s0_false.jpg vs End https://dtexg3-images.s3.ap-southeast-2.amazonaws.com/mobile_uploads/20250514-164401-lgnixh_cc9c5d06-72be-49f1-a3ce-a005b450bf88_3_eoa_12568_-33.7508916_150.693301_android_34_11p03-01_b0_s0_true.jpg: SSIM = 0.3782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching Labels to Ends:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:10<00:03,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label https://dtexg3-images.s3.ap-southeast-2.amazonaws.com/mobile_uploads/20250514-164417-bUZfVV_cc9c5d06-72be-49f1-a3ce-a005b450bf88_3_eoa_12568_-33.7508916_150.693301_android_34_11p03-01_b0_s0_false.jpg vs End https://dtexg3-images.s3.ap-southeast-2.amazonaws.com/mobile_uploads/20250514-164401-lgnixh_cc9c5d06-72be-49f1-a3ce-a005b450bf88_3_eoa_12568_-33.7508916_150.693301_android_34_11p03-01_b0_s0_true.jpg: SSIM = 0.3814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching Labels to Ends: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:13<00:00,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label https://dtexg3-images.s3.ap-southeast-2.amazonaws.com/mobile_uploads/20250514-164404-NFkyfx_cc9c5d06-72be-49f1-a3ce-a005b450bf88_3_eoa_12568_-33.7508916_150.693301_android_34_11p03-01_b0_s0_false.jpg vs End https://dtexg3-images.s3.ap-southeast-2.amazonaws.com/mobile_uploads/20250514-164401-lgnixh_cc9c5d06-72be-49f1-a3ce-a005b450bf88_3_eoa_12568_-33.7508916_150.693301_android_34_11p03-01_b0_s0_true.jpg: SSIM = 0.4071\n",
      "âœ… SSIM matching complete. Results saved to 'ssim_results_filtered.csv'.\n",
      "                                 label_end_image_url best_end_image_url  \\\n",
      "0  https://dtexg3-images.s3.ap-southeast-2.amazon...               None   \n",
      "1  https://dtexg3-images.s3.ap-southeast-2.amazon...               None   \n",
      "2  https://dtexg3-images.s3.ap-southeast-2.amazon...               None   \n",
      "3  https://dtexg3-images.s3.ap-southeast-2.amazon...               None   \n",
      "\n",
      "   ssim_score  \n",
      "0          -1  \n",
      "1          -1  \n",
      "2          -1  \n",
      "3          -1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import requests\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1ï¸âƒ£ Load your report data\n",
    "df = pd.read_csv(\"20250514-report.csv\", parse_dates=['date_captured'])\n",
    "df.columns = df.columns.str.strip().str.replace('\"', '')\n",
    "\n",
    "# 2ï¸âƒ£ Filter for a specific date (e.g., 14th May 2025)\n",
    "target_time = pd.Timestamp(\"2025-05-14 16:44:00\")\n",
    "\n",
    "df = df[df['date_captured'] == target_time]\n",
    "print(f\"âœ… Filtered {len(df)} rows for date {target_time}\")\n",
    "\n",
    "# 3ï¸âƒ£ Split into Ends (sku == '-') and Labels (sku != '-')\n",
    "ends_df = df[df['sku'] == '-'].copy()\n",
    "labels_df = df[df['sku'] != '-'].copy()\n",
    "\n",
    "ends_df.to_csv(\"filtered_ends.csv\", index=False)\n",
    "labels_df.to_csv(\"filtered_labels.csv\", index=False)\n",
    "\n",
    "print(f\"âœ… Saved {len(ends_df)} ends and {len(labels_df)} labels.\")\n",
    "\n",
    "# 4ï¸âƒ£ Define function to load image from URL\n",
    "def load_image_from_url(url, color=cv2.IMREAD_GRAYSCALE):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        img_array = np.asarray(bytearray(response.content), dtype=np.uint8)\n",
    "        return cv2.imdecode(img_array, color)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# 5ï¸âƒ£ Match Labels to Ends using SSIM\n",
    "results = []\n",
    "for idx, label_row in tqdm(labels_df.iterrows(), total=len(labels_df), desc=\"Matching Labels to Ends\"):\n",
    "    label_url = label_row['end_image_url']\n",
    "    label_img = load_image_from_url(label_url)\n",
    "    if label_img is None:\n",
    "        continue\n",
    "\n",
    "    best_score = -1\n",
    "    best_end_url = None\n",
    "\n",
    "    for _, end_row in ends_df.iterrows():\n",
    "        end_url = end_row['end_image_url']\n",
    "        end_img = load_image_from_url(end_url)\n",
    "        if end_img is None:\n",
    "            continue\n",
    "\n",
    "    try:\n",
    "        # label_resized = cv2.resize(label_img, (500, 500))\n",
    "        # end_resized = cv2.resize(end_img, (500, 500))\n",
    "        score, _ = ssim(end_img, label_img, full=True)\n",
    "        print(f\"Label {label_url} vs End {end_url}: SSIM = {score:.4f}\")\n",
    "    except:\n",
    "        score = np.nan\n",
    "\n",
    "        # try:\n",
    "        #     # label_resized = cv2.resize(label_img, (500, 500))\n",
    "        #     # end_resized = cv2.resize(end_img, (500, 500))\n",
    "        #     score, _ = ssim(end_img, label_img, full=True)\n",
    "        # except:\n",
    "        #     score = np.nan\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_end_url = end_url\n",
    "\n",
    "    results.append({\n",
    "        'label_end_image_url': label_url,\n",
    "        'best_end_image_url': best_end_url,\n",
    "        'ssim_score': best_score\n",
    "    })\n",
    "\n",
    "# 6ï¸âƒ£ Save Results\n",
    "ssim_results_df = pd.DataFrame(results)\n",
    "ssim_results_df.to_csv(\"ssim_results_filtered.csv\", index=False)\n",
    "\n",
    "print(\"âœ… SSIM matching complete. Results saved to 'ssim_results_filtered.csv'.\")\n",
    "print(ssim_results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: date_captured, dtype: datetime64[ns])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['date_captured']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vrajnena/Desktop/Ml/myenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/var/folders/l6/jvk_psqj1mz2tbsrq4j601_w0000gn/T/ipykernel_58666/1967673171.py:30: UserWarning: Parsing dates in %d/%m/%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df = pd.read_csv(\"20250514-report.csv\", parse_dates=['date_captured'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Filtered 8 rows for exact datetime 2025-05-14 16:44:00\n",
      "âœ… 4 ends and 4 labels found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:13<00:00,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Cosine similarity matching complete!\n",
      "                                 label_end_image_url  \\\n",
      "0  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "1  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "2  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "3  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "\n",
      "                                  best_end_image_url  cosine_similarity  \n",
      "0  https://dtexg3-images.s3.ap-southeast-2.amazon...           0.787084  \n",
      "1  https://dtexg3-images.s3.ap-southeast-2.amazon...           0.770264  \n",
      "2  https://dtexg3-images.s3.ap-southeast-2.amazon...           0.830588  \n",
      "3  https://dtexg3-images.s3.ap-southeast-2.amazon...           0.816342  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load CLIP Model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "# Function to get CLIP embeddings\n",
    "def get_clip_embedding(url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "        inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            embedding = model.get_image_features(**inputs)\n",
    "        return embedding.cpu().numpy().flatten()\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Load report data\n",
    "df = pd.read_csv(\"20250514-report.csv\", parse_dates=['date_captured'])\n",
    "df.columns = df.columns.str.strip().str.replace('\"', '')\n",
    "\n",
    "# Filter for specific date (no time window)\n",
    "target_datetime = pd.Timestamp(\"2025-05-14 16:44:00\")\n",
    "\n",
    "filtered_df = df[df['date_captured'] == target_datetime].copy()\n",
    "print(f\"âœ… Filtered {len(filtered_df)} rows for exact datetime {target_datetime}\")\n",
    "\n",
    "# Split into ends and labels\n",
    "ends_df = filtered_df[filtered_df['sku'] == '-'].copy()\n",
    "labels_df = filtered_df[filtered_df['sku'] != '-'].copy()\n",
    "\n",
    "print(f\"âœ… {len(ends_df)} ends and {len(labels_df)} labels found.\")\n",
    "\n",
    "# Cosine Similarity Matching\n",
    "results = []\n",
    "for idx, label_row in tqdm(labels_df.iterrows(), total=len(labels_df), desc=\"Matching\"):\n",
    "    label_emb = get_clip_embedding(label_row['end_image_url'])\n",
    "    if label_emb is None:\n",
    "        continue\n",
    "\n",
    "    best_score = -1\n",
    "    best_end_url = None\n",
    "\n",
    "    for _, end_row in ends_df.iterrows():\n",
    "        end_emb = get_clip_embedding(end_row['end_image_url'])\n",
    "        if end_emb is None:\n",
    "            continue\n",
    "\n",
    "        score = cosine_similarity([label_emb], [end_emb])[0][0]\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_end_url = end_row['end_image_url']\n",
    "\n",
    "    results.append({\n",
    "        'label_end_image_url': label_row['end_image_url'],\n",
    "        'best_end_image_url': best_end_url,\n",
    "        'cosine_similarity': best_score\n",
    "    })\n",
    "\n",
    "# Save results\n",
    "cosine_results_df = pd.DataFrame(results)\n",
    "cosine_results_df.to_csv(\"cosine_similarity_results.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Cosine similarity matching complete!\")\n",
    "print(cosine_results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Parsing dates in %d/%m/%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Filtered: 4 ends and 4 labels for 2025-05-14 16:44:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching:   0%|          | 0/4 [00:00<?, ?it/s]FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Error in detect_regions for https://dtexg3-images.s3.ap-southeast-2.amazonaws.com/mobile_uploads/20250514-164414-szsjlq_cc9c5d06-72be-49f1-a3ce-a005b450bf88_3_eoa_12568_-33.7508916_150.693301_android_34_11p03-01_b0_s0_false.jpg: not supported\n",
      "âŒ Error in detect_regions for https://dtexg3-images.s3.ap-southeast-2.amazonaws.com/mobile_uploads/20250514-164449-9q8J4Y_cc9c5d06-72be-49f1-a3ce-a005b450bf88_3_eoa_12568_-33.7508916_150.693301_android_34_11p03-01_b0_s0_false.jpg: not supported\n",
      "âŒ Error in detect_regions for https://dtexg3-images.s3.ap-southeast-2.amazonaws.com/mobile_uploads/20250514-164427-sVfMHi_cc9c5d06-72be-49f1-a3ce-a005b450bf88_3_eoa_12568_-33.7508916_150.693301_android_34_11p03-01_b0_s0_false.jpg: not supported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:02<00:08,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Error in detect_regions for https://dtexg3-images.s3.ap-southeast-2.amazonaws.com/mobile_uploads/20250514-164401-lgnixh_cc9c5d06-72be-49f1-a3ce-a005b450bf88_3_eoa_12568_-33.7508916_150.693301_android_34_11p03-01_b0_s0_true.jpg: not supported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Error in detect_regions for https://dtexg3-images.s3.ap-southeast-2.amazonaws.com/mobile_uploads/20250514-164414-szsjlq_cc9c5d06-72be-49f1-a3ce-a005b450bf88_3_eoa_12568_-33.7508916_150.693301_android_34_11p03-01_b0_s0_false.jpg: not supported\n",
      "âŒ Error in detect_regions for https://dtexg3-images.s3.ap-southeast-2.amazonaws.com/mobile_uploads/20250514-164449-9q8J4Y_cc9c5d06-72be-49f1-a3ce-a005b450bf88_3_eoa_12568_-33.7508916_150.693301_android_34_11p03-01_b0_s0_false.jpg: not supported\n",
      "âŒ Error in detect_regions for https://dtexg3-images.s3.ap-southeast-2.amazonaws.com/mobile_uploads/20250514-164427-sVfMHi_cc9c5d06-72be-49f1-a3ce-a005b450bf88_3_eoa_12568_-33.7508916_150.693301_android_34_11p03-01_b0_s0_false.jpg: not supported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:05,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Error in detect_regions for https://dtexg3-images.s3.ap-southeast-2.amazonaws.com/mobile_uploads/20250514-164401-lgnixh_cc9c5d06-72be-49f1-a3ce-a005b450bf88_3_eoa_12568_-33.7508916_150.693301_android_34_11p03-01_b0_s0_true.jpg: not supported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Error in detect_regions for https://dtexg3-images.s3.ap-southeast-2.amazonaws.com/mobile_uploads/20250514-164414-szsjlq_cc9c5d06-72be-49f1-a3ce-a005b450bf88_3_eoa_12568_-33.7508916_150.693301_android_34_11p03-01_b0_s0_false.jpg: not supported\n",
      "âŒ Error in detect_regions for https://dtexg3-images.s3.ap-southeast-2.amazonaws.com/mobile_uploads/20250514-164449-9q8J4Y_cc9c5d06-72be-49f1-a3ce-a005b450bf88_3_eoa_12568_-33.7508916_150.693301_android_34_11p03-01_b0_s0_false.jpg: not supported\n",
      "âŒ Error in detect_regions for https://dtexg3-images.s3.ap-southeast-2.amazonaws.com/mobile_uploads/20250514-164427-sVfMHi_cc9c5d06-72be-49f1-a3ce-a005b450bf88_3_eoa_12568_-33.7508916_150.693301_android_34_11p03-01_b0_s0_false.jpg: not supported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:08<00:02,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Error in detect_regions for https://dtexg3-images.s3.ap-southeast-2.amazonaws.com/mobile_uploads/20250514-164401-lgnixh_cc9c5d06-72be-49f1-a3ce-a005b450bf88_3_eoa_12568_-33.7508916_150.693301_android_34_11p03-01_b0_s0_true.jpg: not supported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Error in detect_regions for https://dtexg3-images.s3.ap-southeast-2.amazonaws.com/mobile_uploads/20250514-164414-szsjlq_cc9c5d06-72be-49f1-a3ce-a005b450bf88_3_eoa_12568_-33.7508916_150.693301_android_34_11p03-01_b0_s0_false.jpg: not supported\n",
      "âŒ Error in detect_regions for https://dtexg3-images.s3.ap-southeast-2.amazonaws.com/mobile_uploads/20250514-164449-9q8J4Y_cc9c5d06-72be-49f1-a3ce-a005b450bf88_3_eoa_12568_-33.7508916_150.693301_android_34_11p03-01_b0_s0_false.jpg: not supported\n",
      "âŒ Error in detect_regions for https://dtexg3-images.s3.ap-southeast-2.amazonaws.com/mobile_uploads/20250514-164427-sVfMHi_cc9c5d06-72be-49f1-a3ce-a005b450bf88_3_eoa_12568_-33.7508916_150.693301_android_34_11p03-01_b0_s0_false.jpg: not supported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:11<00:00,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Error in detect_regions for https://dtexg3-images.s3.ap-southeast-2.amazonaws.com/mobile_uploads/20250514-164401-lgnixh_cc9c5d06-72be-49f1-a3ce-a005b450bf88_3_eoa_12568_-33.7508916_150.693301_android_34_11p03-01_b0_s0_true.jpg: not supported\n",
      "âœ… Matching complete! Results saved to 'groundingdino_clip_results.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import requests\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Add GroundingDINO path\n",
    "import sys\n",
    "sys.path.append(\"/Users/vrajnena/Desktop/Ml/GroundingDINO\")\n",
    "from groundingdino.util.inference import load_model, predict, load_image\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "# ===================\n",
    "# ðŸ”¹ Load Models\n",
    "# ===================\n",
    "# \n",
    "\n",
    "# GroundingDINO\n",
    "dino_config = \"/Users/vrajnena/Desktop/Ml/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\"\n",
    "dino_weights = \"/Users/vrajnena/Desktop/Ml/GroundingDINO/weights/groundingdino_swint_ogc.pth\"\n",
    "dino_model = load_model(dino_config, dino_weights)\n",
    "\n",
    "# CLIP\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "# ===================\n",
    "# ðŸ”¹ Functions\n",
    "# ===================\n",
    "def download_image_to_temp(url, max_retries=3, timeout=30):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.get(url, timeout=timeout)\n",
    "            response.raise_for_status()\n",
    "            with tempfile.NamedTemporaryFile(suffix=\".jpg\", delete=False) as f:\n",
    "                f.write(response.content)\n",
    "                return f.name\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Attempt {attempt+1} failed for {url}: {e}\")\n",
    "            time.sleep(1)\n",
    "    print(f\"âŒ Failed to download image after {max_retries} attempts: {url}\")\n",
    "    return None\n",
    "\n",
    "def get_clip_embedding(img_pil):\n",
    "    try:\n",
    "        inputs = clip_processor(images=img_pil, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            emb = clip_model.get_image_features(**inputs)\n",
    "        return emb.cpu().numpy().flatten()\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ CLIP embedding failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def detect_regions(end_url, prompt):\n",
    "    try:\n",
    "        temp_path = download_image_to_temp(end_url)\n",
    "        if temp_path is None:\n",
    "            return []\n",
    "\n",
    "        img_pil, image_tensor = load_image(temp_path)\n",
    "        image_tensor = image_tensor.unsqueeze(0)\n",
    "        # print(image_tensor)\n",
    "\n",
    "        boxes, logits, phrases = predict(\n",
    "            model=dino_model,\n",
    "            image=image_tensor,\n",
    "            caption=prompt,\n",
    "            box_threshold=0.3,\n",
    "            text_threshold=0.25\n",
    "        )\n",
    "\n",
    "        W, H = img_pil.size\n",
    "        crops = []\n",
    "        for box in boxes:\n",
    "            x0, y0, x1, y1 = box\n",
    "            x0, y0, x1, y1 = int(x0 * W), int(y0 * H), int(x1 * W), int(y1 * H)\n",
    "            crop = img_pil.crop((x0, y0, x1, y1))\n",
    "            crops.append(crop)\n",
    "        print(crops)\n",
    "        os.remove(temp_path)  # Clean up\n",
    "        return crops\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in detect_regions for {end_url}: {e}\")\n",
    "        return []\n",
    "\n",
    "# ===================\n",
    "# ðŸ”¹ Load Data\n",
    "# ===================\n",
    "df = pd.read_csv(\"20250514-report.csv\", parse_dates=['date_captured'])\n",
    "df.columns = df.columns.str.strip().str.replace('\"', '')\n",
    "\n",
    "# Filter for specific datetime\n",
    "target_time = pd.Timestamp(\"2025-05-14 16:44:00\")\n",
    "filtered = df[df['date_captured'] == target_time]\n",
    "ends_df = filtered[filtered['sku'] == '-']\n",
    "labels_df = filtered[filtered['sku'] != '-']\n",
    "\n",
    "print(f\"âœ… Filtered: {len(ends_df)} ends and {len(labels_df)} labels for {target_time}\")\n",
    "\n",
    "# ===================\n",
    "# ðŸ”¹ Matching Process\n",
    "# ===================\n",
    "results = []\n",
    "for idx, label_row in tqdm(labels_df.iterrows(), total=len(labels_df), desc=\"Matching\"):\n",
    "    label_url = label_row['end_image_url']\n",
    "    temp_label_path = download_image_to_temp(label_url)\n",
    "    if temp_label_path is None:\n",
    "        continue\n",
    "\n",
    "    label_img = Image.open(temp_label_path).convert(\"RGB\")\n",
    "    label_emb = get_clip_embedding(label_img)\n",
    "    os.remove(temp_label_path)\n",
    "\n",
    "    if label_emb is None:\n",
    "        continue\n",
    "\n",
    "    best_score, best_end_url = -1, None\n",
    "\n",
    "    for _, end_row in ends_df.iterrows():\n",
    "        end_url = end_row['end_image_url']\n",
    "        regions = detect_regions(end_url, prompt=\"price tag, product label, discount tag\")\n",
    "\n",
    "        for region in regions:\n",
    "            region_emb = get_clip_embedding(region)\n",
    "            if region_emb is None:\n",
    "                continue\n",
    "            score = cosine_similarity([label_emb], [region_emb])[0][0]\n",
    "\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_end_url = end_url\n",
    "\n",
    "    results.append({\n",
    "        'label_end_image_url': label_url,\n",
    "        'best_end_image_url': best_end_url,\n",
    "        'cosine_similarity': best_score,\n",
    "        'label_product': label_row.get('product_name', ''),\n",
    "        'label_brand': label_row.get('brand', ''),\n",
    "    })\n",
    "\n",
    "# ===================\n",
    "# ðŸ”¹ Save Results\n",
    "# ===================\n",
    "pd.DataFrame(results).to_csv(\"groundingdino_clip_results.csv\", index=False)\n",
    "print(\"âœ… Matching complete! Results saved to 'groundingdino_clip_results.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Parsing dates in %d/%m/%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Filtered 4 ends and 4 labels for 2025-05-14 16:44:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching Labels:   0%|          | 0/4 [00:00<?, ?it/s]FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "Matching Labels:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.17s/it]FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "Matching Labels:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:10<00:10,  5.11s/it]FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "Matching Labels:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:14<00:04,  4.82s/it]FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "Matching Labels: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:19<00:00,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Matching complete! Results saved to 'groundingdino_clip_results.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Final Pipeline Script - Part 1\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "import time\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "# Import GroundingDINO\n",
    "import sys\n",
    "sys.path.append(\"/Users/vrajnena/Desktop/Ml/GroundingDINO\")\n",
    "from groundingdino.util.inference import load_model, predict, load_image\n",
    "\n",
    "# ================================\n",
    "# ðŸ”¹ Model Setup\n",
    "# ================================\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load GroundingDINO\n",
    "dino_config = \"GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\"\n",
    "dino_weights = \"GroundingDINO/weights/groundingdino_swint_ogc.pth\"\n",
    "dino_model = load_model(dino_config, dino_weights).to(device)\n",
    "\n",
    "# Load CLIP\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "# ================================\n",
    "# ðŸ”¹ Helper Functions\n",
    "# ================================\n",
    "def download_image(url, retries=3, timeout=30):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = requests.get(url, timeout=timeout)\n",
    "            response.raise_for_status()\n",
    "            return Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Attempt {attempt+1} failed for {url}: {e}\")\n",
    "            time.sleep(1)\n",
    "    print(f\"âŒ Failed to download image: {url}\")\n",
    "    return None\n",
    "\n",
    "def get_clip_embedding(pil_image):\n",
    "    try:\n",
    "        inputs = clip_processor(images=pil_image, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            features = clip_model.get_image_features(**inputs)\n",
    "        return features.cpu().numpy().flatten()\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ CLIP embedding error: {e}\")\n",
    "        return None\n",
    "\n",
    "def detect_dino_regions(pil_image, prompt=\"price tag, product label, discount tag\"):\n",
    "    try:\n",
    "        # Preprocess for GroundingDINO\n",
    "        image_tensor = clip_processor(images=pil_image, return_tensors=\"pt\")['pixel_values'].to(device)\n",
    "        image_tensor = image_tensor.squeeze(0)\n",
    "\n",
    "        W, H = pil_image.size\n",
    "        boxes, logits, phrases = predict(\n",
    "            model=dino_model,\n",
    "            image=image_tensor,\n",
    "            caption=prompt,\n",
    "            box_threshold=0.3,\n",
    "            text_threshold=0.25\n",
    "        )\n",
    "\n",
    "        crops = []\n",
    "        for box in boxes:\n",
    "            x0, y0, x1, y1 = box\n",
    "            # Convert to pixel coordinates\n",
    "            x0, x1 = sorted([int(x0 * W), int(x1 * W)])\n",
    "            y0, y1 = sorted([int(y0 * H), int(y1 * H)])\n",
    "            # Ensure valid box\n",
    "            x0 = max(0, x0)\n",
    "            y0 = max(0, y0)\n",
    "            x1 = min(W, x1)\n",
    "            y1 = min(H, y1)\n",
    "            if x1 - x0 <= 0 or y1 - y0 <= 0:\n",
    "                continue  # Skip invalid boxes\n",
    "            crops.append(pil_image.crop((x0, y0, x1, y1)))\n",
    "\n",
    "        return crops\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ DINO detection error: {e}\")\n",
    "        return []\n",
    "# ================================\n",
    "# ðŸ”¹ Load Data\n",
    "# ================================\n",
    "df = pd.read_csv(\"20250514-report.csv\", parse_dates=['date_captured'])\n",
    "df.columns = df.columns.str.strip().str.replace('\"', '')\n",
    "\n",
    "target_time = pd.Timestamp(\"2025-05-14 16:44:00\")\n",
    "filtered = df[df['date_captured'] == target_time]\n",
    "ends_df = filtered[filtered['sku'] == '-']\n",
    "labels_df = filtered[filtered['sku'] != '-']\n",
    "\n",
    "print(f\"âœ… Filtered {len(ends_df)} ends and {len(labels_df)} labels for {target_time}\")\n",
    "\n",
    "# ================================\n",
    "# ðŸ”¹ Visual-First Matching\n",
    "# ================================\n",
    "results = []\n",
    "for idx, label_row in tqdm(labels_df.iterrows(), total=len(labels_df), desc=\"Matching Labels\"):\n",
    "    label_url = label_row['end_image_url']\n",
    "    label_img = download_image(label_url)\n",
    "    if label_img is None:\n",
    "        continue\n",
    "\n",
    "    label_emb = get_clip_embedding(label_img)\n",
    "    if label_emb is None:\n",
    "        continue\n",
    "\n",
    "    best_score, best_end_url = -1, None\n",
    "\n",
    "    for _, end_row in ends_df.iterrows():\n",
    "        end_url = end_row['end_image_url']\n",
    "        end_img = download_image(end_url)\n",
    "        if end_img is None:\n",
    "            continue\n",
    "\n",
    "        regions = detect_dino_regions(end_img)\n",
    "        for region in regions:\n",
    "            region_emb = get_clip_embedding(region)\n",
    "            if region_emb is None:\n",
    "                continue\n",
    "            score = cosine_similarity([label_emb], [region_emb])[0][0]\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_end_url = end_url\n",
    "\n",
    "    results.append({\n",
    "        'label_end_image_url': label_url,\n",
    "        'best_end_image_url': best_end_url,\n",
    "        'cosine_similarity': best_score,\n",
    "        'label_product': label_row.get('product_name', ''),\n",
    "        'label_brand': label_row.get('brand', ''),\n",
    "    })\n",
    "\n",
    "pd.DataFrame(results).to_csv(\"groundingdino_clip_results.csv\", index=False)\n",
    "print(\"âœ… Matching complete! Results saved to 'groundingdino_clip_results.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Running OCR for End Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… OCR complete. Saved to 'ends_with_ocr.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching Labels to Ends: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Final mapping saved to 'gcv_label_to_end_mapping.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.cloud import vision\n",
    "from google.oauth2 import service_account\n",
    "from fuzzywuzzy import fuzz\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ====================================\n",
    "# 1ï¸âƒ£ Google Cloud Client Setup\n",
    "# ====================================\n",
    "SERVICE_ACCOUNT_JSON = \"/Users/vrajnena/Desktop/Ml/upbeat-airfoil-439209-q3-ab31c54e6301.json\"  # <-- Update\n",
    "credentials = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_JSON)\n",
    "client = vision.ImageAnnotatorClient(credentials=credentials)\n",
    "\n",
    "# ====================================\n",
    "# 2ï¸âƒ£ OCR Function for GCS URL\n",
    "# ====================================\n",
    "def extract_text_from_gcs(gcs_uri):\n",
    "    image = vision.Image()\n",
    "    image.source.image_uri = gcs_uri\n",
    "\n",
    "    response = client.document_text_detection(image=image)\n",
    "    if response.error.message:\n",
    "        print(f\"âŒ Error in Vision API: {response.error.message}\")\n",
    "        return \"\"\n",
    "\n",
    "    text = response.full_text_annotation.text\n",
    "    return text\n",
    "\n",
    "# ====================================\n",
    "# 3ï¸âƒ£ Matching Logic\n",
    "# ====================================\n",
    "def match_labels_to_ends(labels_df, ends_df):\n",
    "    results = []\n",
    "    for idx, label_row in tqdm(labels_df.iterrows(), total=len(labels_df), desc=\"Matching Labels to Ends\"):\n",
    "        label_text = f\"{label_row['brand']} {label_row['product_name']}\"\n",
    "\n",
    "        best_score = -1\n",
    "        best_end_url = None\n",
    "        for _, end_row in ends_df.iterrows():\n",
    "            end_text = end_row['ocr_text']\n",
    "            score = fuzz.token_set_ratio(label_text, end_text)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_end_url = end_row['end_image_url']\n",
    "\n",
    "        results.append({\n",
    "            'label_image_url': label_row['label_image_url'],\n",
    "            'best_end_image_url': best_end_url,\n",
    "            'fuzzy_score': best_score,\n",
    "            'label_text': label_text\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# ====================================\n",
    "# 4ï¸âƒ£ Load Data (from your report)\n",
    "# ====================================\n",
    "df = pd.read_csv(\"20250514-report.csv\")\n",
    "df.columns = df.columns.str.strip().str.replace('\"', '')\n",
    "\n",
    "# Filter for specific datetime\n",
    "target_time = pd.Timestamp(\"2025-05-14 16:44:00\")\n",
    "filtered = df[df['date_captured'] == target_time]\n",
    "\n",
    "# Split into Ends (sku == '-') and Labels (sku != '-')\n",
    "ends_df = filtered[filtered['sku'] == '-'].copy()\n",
    "labels_df = filtered[filtered['sku'] != '-'].copy()\n",
    "\n",
    "# ====================================\n",
    "# 5ï¸âƒ£ Extract OCR for Ends\n",
    "# ====================================\n",
    "print(\"ðŸ” Running OCR for End Images...\")\n",
    "ocr_texts = []\n",
    "for url in tqdm(ends_df['end_image_url']):\n",
    "    text = extract_text_from_gcs(url)\n",
    "    ocr_texts.append(text)\n",
    "ends_df['ocr_text'] = ocr_texts\n",
    "\n",
    "# Save OCR results\n",
    "ends_df.to_csv(\"ends_with_ocr.csv\", index=False)\n",
    "print(\"âœ… OCR complete. Saved to 'ends_with_ocr.csv'.\")\n",
    "\n",
    "# ====================================\n",
    "# 6ï¸âƒ£ Match Labels to Ends\n",
    "# ====================================\n",
    "matched_df = match_labels_to_ends(labels_df, ends_df)\n",
    "matched_df.to_csv(\"gcv_label_to_end_mapping.csv\", index=False)\n",
    "print(\"âœ… Final mapping saved to 'gcv_label_to_end_mapping.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_csv(\"20250514-report.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "424"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['brand'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip().str.replace('\"', '')\n",
    "\n",
    "# Filter out NaN and deduplicate\n",
    "unique_products = df[['brand', 'product_name', 'pack_size','end_image_url']].dropna().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: Index.format is deprecated and will be removed in a future version. Convert using index.astype(str) or index.map(formatter) instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>product_name</th>\n",
       "      <th>pack_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RED TRACTOR</td>\n",
       "      <td>AUSTRALIAN ROLLED OATS</td>\n",
       "      <td>1KG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gold Sunset</td>\n",
       "      <td>Canola Oil</td>\n",
       "      <td>2L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SISTEMA</td>\n",
       "      <td>ULTRA CONTAINER 4L</td>\n",
       "      <td>1 EACH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DECOR</td>\n",
       "      <td>QUAD BANDS TRITAN BOTTLE 750ML</td>\n",
       "      <td>1 EACH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4375</th>\n",
       "      <td>NONE</td>\n",
       "      <td>MATT MORANSTOCK CHICKEN</td>\n",
       "      <td>500ML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4378</th>\n",
       "      <td>CAMPBELLS</td>\n",
       "      <td>CAMPBELLS COUNTRY LADLE SOUP MINESTRONE</td>\n",
       "      <td>495G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4380</th>\n",
       "      <td>CAPTAINS TABLE</td>\n",
       "      <td>CAPTAINS TABLE WATER CRACKER</td>\n",
       "      <td>125G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4387</th>\n",
       "      <td>HEINZ</td>\n",
       "      <td>HEINZ CLASSIC PEA &amp; HAM SOUP CANNED SOUP READY...</td>\n",
       "      <td>535G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4389</th>\n",
       "      <td>BARILLA</td>\n",
       "      <td>BARILLA PASTA SPAGHETTI PASTA NO 5</td>\n",
       "      <td>500G</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1673 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               brand                                       product_name  \\\n",
       "0                  -                                                  -   \n",
       "1        RED TRACTOR                             AUSTRALIAN ROLLED OATS   \n",
       "2        Gold Sunset                                         Canola Oil   \n",
       "3            SISTEMA                                 ULTRA CONTAINER 4L   \n",
       "4              DECOR                     QUAD BANDS TRITAN BOTTLE 750ML   \n",
       "...              ...                                                ...   \n",
       "4375            NONE                            MATT MORANSTOCK CHICKEN   \n",
       "4378       CAMPBELLS            CAMPBELLS COUNTRY LADLE SOUP MINESTRONE   \n",
       "4380  CAPTAINS TABLE                       CAPTAINS TABLE WATER CRACKER   \n",
       "4387           HEINZ  HEINZ CLASSIC PEA & HAM SOUP CANNED SOUP READY...   \n",
       "4389         BARILLA                 BARILLA PASTA SPAGHETTI PASTA NO 5   \n",
       "\n",
       "     pack_size  \n",
       "0            -  \n",
       "1          1KG  \n",
       "2           2L  \n",
       "3       1 EACH  \n",
       "4       1 EACH  \n",
       "...        ...  \n",
       "4375     500ML  \n",
       "4378      495G  \n",
       "4380      125G  \n",
       "4387      535G  \n",
       "4389      500G  \n",
       "\n",
       "[1673 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Lengths must match to compare', (3289,), (2,))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     12\u001b[39m unique_products = df[(df[\u001b[33m'\u001b[39m\u001b[33mstore_type\u001b[39m\u001b[33m'\u001b[39m] == \u001b[33m'\u001b[39m\u001b[33mColes\u001b[39m\u001b[33m'\u001b[39m)][\u001b[33m'\u001b[39m\u001b[33mproduct_name\u001b[39m\u001b[33m'\u001b[39m].dropna().unique()\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# selected_product = st.sidebar.selectbox(\"Select Product\", unique_products)\u001b[39;00m\n\u001b[32m     14\u001b[39m \n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Filtered Data\u001b[39;00m\n\u001b[32m     16\u001b[39m filtered_df = df[\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     (\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstore_type\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore_types\u001b[49m) &\n\u001b[32m     18\u001b[39m     (df[\u001b[33m'\u001b[39m\u001b[33mstore_suburb\u001b[39m\u001b[33m'\u001b[39m] == store_suburbs) &\n\u001b[32m     19\u001b[39m     (df[\u001b[33m'\u001b[39m\u001b[33mproduct_name\u001b[39m\u001b[33m'\u001b[39m] == unique_products)\n\u001b[32m     20\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Ml/myenv/lib/python3.12/site-packages/pandas/core/ops/common.py:76\u001b[39m, in \u001b[36mnew_method\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Ml/myenv/lib/python3.12/site-packages/pandas/core/arraylike.py:40\u001b[39m, in \u001b[36m__eq__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_cmp_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m__eq__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._cmp_method(other, operator.eq)\n\u001b[32m     44\u001b[39m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m__ne__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__ne__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Ml/myenv/lib/python3.12/site-packages/pandas/core/series.py:6119\u001b[39m, in \u001b[36m_cmp_method\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m   6114\u001b[39m     ...\n\u001b[32m   6116\u001b[39m \u001b[38;5;66;03m# error: Signature of \"where\" incompatible with supertype \"NDFrame\"\u001b[39;00m\n\u001b[32m   6117\u001b[39m \u001b[38;5;129m@deprecate_kwarg\u001b[39m(old_arg_name=\u001b[33m\"\u001b[39m\u001b[33merrors\u001b[39m\u001b[33m\"\u001b[39m, new_arg_name=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   6118\u001b[39m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(\n\u001b[32m-> \u001b[39m\u001b[32m6119\u001b[39m     version=\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args=[\u001b[33m\"\u001b[39m\u001b[33mself\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcond\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mother\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   6120\u001b[39m )\n\u001b[32m   6121\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwhere\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[32m   6122\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   6123\u001b[39m     cond,\n\u001b[32m   6124\u001b[39m     other=lib.no_default,\n\u001b[32m   6125\u001b[39m     inplace: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   6126\u001b[39m     axis: Axis | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   6127\u001b[39m     level: Level = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   6128\u001b[39m     errors: IgnoreRaise | lib.NoDefault = lib.no_default,\n\u001b[32m   6129\u001b[39m     try_cast: \u001b[38;5;28mbool\u001b[39m | lib.NoDefault = lib.no_default,\n\u001b[32m   6130\u001b[39m ) -> Series | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   6131\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().where(\n\u001b[32m   6132\u001b[39m         cond,\n\u001b[32m   6133\u001b[39m         other,\n\u001b[32m   (...)\u001b[39m\u001b[32m   6137\u001b[39m         try_cast=try_cast,\n\u001b[32m   6138\u001b[39m     )\n\u001b[32m   6140\u001b[39m \u001b[38;5;129m@overload\u001b[39m\n\u001b[32m   6141\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmask\u001b[39m(\n\u001b[32m   6142\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   6150\u001b[39m     try_cast: \u001b[38;5;28mbool\u001b[39m | lib.NoDefault = ...,\n\u001b[32m   6151\u001b[39m ) -> Series:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Ml/myenv/lib/python3.12/site-packages/pandas/core/ops/array_ops.py:321\u001b[39m, in \u001b[36mcomparison_op\u001b[39m\u001b[34m(left, right, op)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    319\u001b[39m     result = libops.scalar_binop(x, y, op)\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m     \u001b[38;5;167;01mTypeError\u001b[39;00m,\n\u001b[32m    322\u001b[39m     \u001b[38;5;167;01mValueError\u001b[39;00m,\n\u001b[32m    323\u001b[39m     \u001b[38;5;167;01mAttributeError\u001b[39;00m,\n\u001b[32m    324\u001b[39m     \u001b[38;5;167;01mOverflowError\u001b[39;00m,\n\u001b[32m    325\u001b[39m     \u001b[38;5;167;01mNotImplementedError\u001b[39;00m,\n\u001b[32m    326\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    327\u001b[39m     typ = \u001b[38;5;28mtype\u001b[39m(y).\u001b[34m__name__\u001b[39m\n\u001b[32m    328\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    329\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot perform \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mop.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m with a dtyped [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] array \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    330\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mand scalar of type [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtyp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    331\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: ('Lengths must match to compare', (3289,), (2,))"
     ]
    }
   ],
   "source": [
    "df = df[~df['end_location'].str.lower().str.contains('off', na=False)].copy()\n",
    "\n",
    "# Sidebar Filters\n",
    "# st.sidebar.title(\"ðŸ›’ Product Filter Dashboard\")\n",
    "\n",
    "store_types = df['store_type'].dropna().unique()\n",
    "# store_type = st.sidebar.selectbox(\"Select Store Type\", store_types)\n",
    "\n",
    "store_suburbs = df[df['store_type'] == 'Coles']['store_suburb'].dropna().unique()\n",
    "# store_suburb = st.sidebar.selectbox(\"Select Store Suburb\", store_suburbs)\n",
    "\n",
    "unique_products = df[(df['store_type'] == 'Coles')]['product_name'].dropna().unique()\n",
    "# selected_product = st.sidebar.selectbox(\"Select Product\", unique_products)\n",
    "\n",
    "# Filtered Data\n",
    "filtered_df = df[\n",
    "    (df['store_type'] == store_types) &\n",
    "    (df['store_suburb'] == store_suburbs) &\n",
    "    (df['product_name'] == unique_products)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 506 ends and 606 labels.\n",
      "âœ… Matching complete! Results saved to 'label_to_end_matches.csv'.\n",
      "        label_id                                    label_image_url  \\\n",
      "0  lblID-1195330  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "1  lblID-1195392  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "2  lblID-1195388  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "3  lblID-1195386  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "4  lblID-1195385  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "\n",
      "                                       label_product  \\\n",
      "0                OREO OREO PASCALL MARSHMALLOWS SLUG   \n",
      "1                      VICKS VICKS VAPOUR SHOWER 5PK   \n",
      "2  DARRELL LEA DARRELL LEA MILK CHOCOLATE LOVE HEART   \n",
      "3       BLACKMORES LYP-SINE COLD SORE RELIEF TABLETS   \n",
      "4        RED BULL SUGAR FREE ENERGY DRINK SINGLE CAN   \n",
      "\n",
      "                                       end_image_url  \\\n",
      "0  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "1  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "2  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "3  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "4  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "\n",
      "                                          matched_on  \n",
      "0  352670|Coles|Croydon| Off Location |2025-05-14...  \n",
      "1  352670|Coles|Croydon| Off Location |2025-05-14...  \n",
      "2  352670|Coles|Croydon| Off Location |2025-05-14...  \n",
      "3  352670|Coles|Croydon| Off Location |2025-05-14...  \n",
      "4  352670|Coles|Croydon| Off Location |2025-05-14...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1ï¸âƒ£ Load the report CSV\n",
    "df = pd.read_csv(\"20250514-report.csv\", parse_dates=['date_captured'])\n",
    "df.columns = df.columns.str.strip().str.replace('\"', '')\n",
    "df =df[df['end_location'].str.contains(\"Off Location\", case=False, na=False)].copy()\n",
    "\n",
    "# 2ï¸âƒ£ Split into Ends (sku == '-') and Labels (sku != '-')\n",
    "ends_df = df[df['sku'] == '-'].copy()\n",
    "labels_df = df[df['sku'] != '-'].copy()\n",
    "\n",
    "print(f\"âœ… Loaded {len(ends_df)} ends and {len(labels_df)} labels.\")\n",
    "\n",
    "# 3ï¸âƒ£ Function to generate a combined key for matching\n",
    "def generate_key(row):\n",
    "    return f\"{row['visit_id']}|{row['store_type']}|{row['store_suburb']}|{row['end_location']}|{row['date_captured']}\"\n",
    "\n",
    "# 4ï¸âƒ£ Create keys for matching\n",
    "ends_df['match_key'] = ends_df.apply(generate_key, axis=1)\n",
    "labels_df['match_key'] = labels_df.apply(generate_key, axis=1)\n",
    "\n",
    "# 5ï¸âƒ£ Match labels to ends based on match_key\n",
    "match_results = []\n",
    "\n",
    "for idx, label_row in labels_df.iterrows():\n",
    "    label_key = label_row['match_key']\n",
    "    candidates = ends_df[ends_df['match_key'] == label_key]\n",
    "\n",
    "    if not candidates.empty:\n",
    "        # Take the first match (can be adjusted if you prefer logic like closest timestamp etc.)\n",
    "        matched_end = candidates.iloc[0]\n",
    "        match_results.append({\n",
    "            'label_id': label_row['id'],\n",
    "            'label_image_url': label_row['label_image_url'],\n",
    "            'label_product': f\"{label_row['brand']} {label_row['product_name']}\",\n",
    "            'end_image_url': matched_end['end_image_url'],\n",
    "            'matched_on': label_key\n",
    "        })\n",
    "    else:\n",
    "        match_results.append({\n",
    "            'label_id': label_row['id'],\n",
    "            'label_image_url': label_row['label_image_url'],\n",
    "            'label_product': f\"{label_row['brand']} {label_row['product_name']}\",\n",
    "            'end_image_url': None,\n",
    "            'matched_on': 'No Match'\n",
    "        })\n",
    "\n",
    "# 6ï¸âƒ£ Convert to DataFrame and save\n",
    "final_matches_df = pd.DataFrame(match_results)\n",
    "final_matches_df.to_csv(\"label_to_end_matches.csv\", index=False)\n",
    "\n",
    "print(f\"âœ… Matching complete! Results saved to 'label_to_end_matches.csv'.\")\n",
    "print(final_matches_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 506 ends and 606 labels.\n",
      "âœ… Matching complete! Results saved to 'label_to_end_matches_filtered.csv'.\n",
      "        label_id                                    label_image_url  \\\n",
      "0  lblID-1195330  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "1  lblID-1195392  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "2  lblID-1195388  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "3  lblID-1195386  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "4  lblID-1195385  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "\n",
      "                                       label_product  \\\n",
      "0                OREO OREO PASCALL MARSHMALLOWS SLUG   \n",
      "1                      VICKS VICKS VAPOUR SHOWER 5PK   \n",
      "2  DARRELL LEA DARRELL LEA MILK CHOCOLATE LOVE HEART   \n",
      "3       BLACKMORES LYP-SINE COLD SORE RELIEF TABLETS   \n",
      "4        RED BULL SUGAR FREE ENERGY DRINK SINGLE CAN   \n",
      "\n",
      "                                       end_image_url  \\\n",
      "0                                               None   \n",
      "1  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "2                                               None   \n",
      "3  https://dtexg3-images.s3.ap-southeast-2.amazon...   \n",
      "4                                               None   \n",
      "\n",
      "                                          matched_on  \n",
      "0                   No Match (multiple ends or none)  \n",
      "1  352670|Coles|Croydon| Off Location |2025-05-14...  \n",
      "2                   No Match (multiple ends or none)  \n",
      "3  352670|Coles|Croydon| Off Location |2025-05-14...  \n",
      "4                   No Match (multiple ends or none)  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1ï¸âƒ£ Load the report CSV\n",
    "df = pd.read_csv(\"20250514-report.csv\", parse_dates=['date_captured'])\n",
    "df.columns = df.columns.str.strip().str.replace('\"', '')\n",
    "df =df[df['end_location'].str.contains(\"Off Location\", case=False, na=False)].copy()\n",
    "\n",
    "# 2ï¸âƒ£ Split into Ends (sku == '-') and Labels (sku != '-')\n",
    "ends_df = df[df['sku'] == '-'].copy()\n",
    "labels_df = df[df['sku'] != '-'].copy()\n",
    "\n",
    "print(f\"âœ… Loaded {len(ends_df)} ends and {len(labels_df)} labels.\")\n",
    "\n",
    "# 3ï¸âƒ£ Function to generate a combined key for matching\n",
    "def generate_key(row):\n",
    "    return f\"{row['visit_id']}|{row['store_type']}|{row['store_suburb']}|{row['end_location']}|{row['date_captured']}\"\n",
    "\n",
    "# 4ï¸âƒ£ Create keys for matching\n",
    "ends_df['match_key'] = ends_df.apply(generate_key, axis=1)\n",
    "labels_df['match_key'] = labels_df.apply(generate_key, axis=1)\n",
    "\n",
    "# 5ï¸âƒ£ Pre-compute counts of ends per key\n",
    "ends_counts = ends_df['match_key'].value_counts().to_dict()\n",
    "\n",
    "# 6ï¸âƒ£ Match labels to ends based on match_key (only if exactly 1 end)\n",
    "match_results = []\n",
    "\n",
    "for idx, label_row in labels_df.iterrows():\n",
    "    label_key = label_row['match_key']\n",
    "    match_count = ends_counts.get(label_key, 0)\n",
    "\n",
    "    if match_count == 1:\n",
    "        matched_end = ends_df[ends_df['match_key'] == label_key].iloc[0]\n",
    "        match_results.append({\n",
    "            'label_id': label_row['id'],\n",
    "            'label_image_url': label_row['label_image_url'],\n",
    "            'label_product': f\"{label_row['brand']} {label_row['product_name']}\",\n",
    "            'end_image_url': matched_end['end_image_url'],\n",
    "            'brand':matched_end['brand']\n",
    "            'matched_on': label_key\n",
    "        })\n",
    "    else:\n",
    "        match_results.append({\n",
    "            'label_id': label_row['id'],\n",
    "            'label_image_url': label_row['label_image_url'],\n",
    "            'label_product': f\"{label_row['brand']} {label_row['product_name']}\",\n",
    "            'end_image_url': None,\n",
    "            'matched_on': 'No Match (multiple ends or none)'\n",
    "        })\n",
    "\n",
    "# 7ï¸âƒ£ Convert to DataFrame and save\n",
    "final_matches_df = pd.DataFrame(match_results)\n",
    "final_matches_df.to_csv(\"label_to_end_matches_filtered.csv\", index=False)\n",
    "\n",
    "print(f\"âœ… Matching complete! Results saved to 'label_to_end_matches_filtered.csv'.\")\n",
    "print(final_matches_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
